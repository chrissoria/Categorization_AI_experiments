{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78c77629",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.prompts.prompt import PromptTemplate #where we change the AI \"personality\"\n",
    "from dotenv import load_dotenv, find_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "129c22b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a25a7471",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "#openai.api_key = os.getenv(\"api.txt\")\n",
    "COMPLETIONS_MODEL = \"text-davinci-002\"\n",
    "BETTER_COMPLETIONS_MODEL = \"text-davinci-003\" #for my purposes, this is better\n",
    "LONG_MODEL = \"gpt-3.5-turbo-16k\"\n",
    "REGULAR_MODEL = \"gpt-3.5-turbo\"\n",
    "GPT_4 = \"gpt-4-1106-preview\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b96d96b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/chrissoria/Documents/Research/Categorization_AI_experiments\n"
     ]
    }
   ],
   "source": [
    "os.chdir('/Users/chrissoria/Documents/Research/Categorization_AI_experiments')\n",
    "current_directory = os.getcwd()\n",
    "print(current_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a7b7a15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a19i</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>relocated back to east coast - closer to my sons</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>move in together with my partner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>out of living with my friends, and into living...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>to take a new job in new york city (both becau...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wanted to live in my own place outside my pare...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                a19i\n",
       "0   relocated back to east coast - closer to my sons\n",
       "1                   move in together with my partner\n",
       "2  out of living with my friends, and into living...\n",
       "3  to take a new job in new york city (both becau...\n",
       "4  wanted to live in my own place outside my pare..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "survey_participant_input = \"a19i\" #enter column name here\n",
    "\n",
    "UCNets = pd.read_excel(\"/Users/chrissoria/Documents/Research/UCNets_Classification/data/Raw_Cond_for_Coding_all_waves.xlsx\", engine='openpyxl',sheet_name=\"JOINT_DATA\",usecols=[survey_participant_input])\n",
    "UCNets = UCNets[survey_participant_input].dropna().unique()  # Drop NaN values and get unique elements\n",
    "\n",
    "survey_participant_responses = '; '.join(str(item) for item in UCNets) #what we will feed to the model\n",
    "\n",
    "UCNets = pd.DataFrame(UCNets, columns=[survey_participant_input])\n",
    "UCNets[survey_participant_input] = UCNets[survey_participant_input].astype(str).str.lower()\n",
    "UCNets[survey_participant_input] = UCNets[survey_participant_input].str.strip()\n",
    "UCNets = UCNets[UCNets[survey_participant_input] != ''].reset_index(drop=True) #trimming all empty rows\n",
    "\n",
    "UCNets = UCNets.iloc[:400]\n",
    "\n",
    "UCNets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b77e00c",
   "metadata": {},
   "source": [
    "Here, I'm trying to \"force\" the model to \"think\" in steps by first A. trying to process the response into its own words and B. having it interact with that object. That is, instead of all steps being given at once, I'm having it think in steps. \n",
    "\n",
    "This time, I will have it think in a \"chain,\" where I will have it output a response and then feed that response back to it in a seperate prompt. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f0b5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_categories(survey_question, \n",
    "                       survey_input,\n",
    "                       user_model,\n",
    "                       creativity,\n",
    "                       categories):\n",
    "    \n",
    "    client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\"))\n",
    "    \n",
    "    categories_str = \"\\n\".join(f\"{i + 1}. {cat}\" for i, cat in enumerate(categories))\n",
    "    cat_num = len(user_categories)\n",
    "    category_dict = {str(i+1): \"0\" for i in range(cat_num)}\n",
    "    example_JSON = json.dumps(category_dict, indent=4)\n",
    "    \n",
    "    link1 = []\n",
    "    extracted_jsons = []\n",
    "    \n",
    "    for response in survey_input:\n",
    "        prompt = f\"\"\"Categorize this survey response \"{response}\" into all of the following reasons for moving and select all that apply: \\\n",
    "        {categories_str} \\\n",
    "        Provide your work in JSON format where the number belonging to each category is the key and a 1 if the category is present and a 0 if it is not present as key values.\"\"\"\n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=user_model,\n",
    "                messages=[\n",
    "                    {'role': 'user', 'content': prompt}\n",
    "                ],\n",
    "                temperature=creativity\n",
    "            )\n",
    "\n",
    "            reply = response.choices[0].message.content\n",
    "            link1.append(reply)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "            link1.append(f\"Error processing input: {input}\")\n",
    "            \n",
    "        extracted_json = re.findall(r'```json\\n(\\{.*?\\})\\n```', reply, re.DOTALL)\n",
    "        extracted_json = extracted_json[0].replace('[', '').replace(']', '').replace('\\n', '').replace(\" \", '').replace(\"  \", '')\n",
    "        print(extracted_json)\n",
    "        extracted_jsons.append(extracted_json)\n",
    "            \n",
    "    normalized_data_list = []\n",
    "    error_lines = []\n",
    "    \n",
    "    for i, json_str in enumerate(extracted_jsons):\n",
    "        try:\n",
    "            parsed_obj = json.loads(json_str)\n",
    "            normalized_data_list.append(pd.json_normalize(parsed_obj))\n",
    "        except json.JSONDecodeError:\n",
    "            normalized_data_list.append(\"\"\"{\"1\":\"e\"}\"\"\")\n",
    "            continue\n",
    "\n",
    "    normalized_data = pd.concat(normalized_data_list, ignore_index=True)\n",
    "    \n",
    "    categorized_data = pd.DataFrame()\n",
    "    categorized_data['survey_response'] = survey_input\n",
    "    categorized_data['link1'] = link1\n",
    "    categorized_data['json'] = extracted_jsons\n",
    "    \n",
    "    categorized_data = pd.concat([categorized_data, normalized_data], axis=1)\n",
    "    \n",
    "    return categorized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae55712c",
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_question = \"Why did you move?\"\n",
    "survey_input = UCNets['a19i']\n",
    "\n",
    "creativity = .0\n",
    "\n",
    "user_categories = [\"to start or continue living with with a partner/spouse\",\n",
    "                   \"related to the person's job, school or career, including transfers, retirement, a new job, or wanting to be closer to work\",\n",
    "                   \"related to their partner's job, school or career, such as transfers, retirement, a new job, wanting to be closer to work\",\n",
    "                   \"financial reasons, such as increases in rent, affordability of the current housing expenses, pay raises\",\n",
    "                   \"related to family members for various reasons, such as providing support, facilitating care, a child's schooling needs, or a new baby\"]\n",
    "\n",
    "user_model = 'gpt-4-1106-preview'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b40959",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bad = extract_categories(survey_question, \n",
    "                            survey_input, \n",
    "                            user_model,\n",
    "                            creativity,\n",
    "                            user_categories)\n",
    "\n",
    "bad.to_csv('data/a19i_bad_categorization_5_cats.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f7c8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(bad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6120e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_categories_improved(survey_question, \n",
    "                       survey_input,\n",
    "                       user_model,\n",
    "                       creativity,\n",
    "                       categories):\n",
    "    \n",
    "    client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\"))\n",
    "    \n",
    "    categories_str = \"\\n\".join(f\"{i + 1}. {cat}\" for i, cat in enumerate(categories))\n",
    "    cat_num = len(user_categories)\n",
    "    category_dict = {str(i+1): \"0\" for i in range(cat_num)}\n",
    "    example_JSON = json.dumps(category_dict, indent=4)\n",
    "    \n",
    "    link1 = []\n",
    "    extracted_jsons = []\n",
    "    \n",
    "    for response in survey_input:\n",
    "        prompt = f\"\"\"A survey respondent was asked, \"{survey_question}\" \\\n",
    "        Their response is here in triple backticks: ```{response}```. \\\n",
    "        Select all of the following numbered categories present in the response and form your response in proper JSON format: \\\n",
    "        The number belonging to the category should be be the key and a 1 is the key value if the category is present. \\\n",
    "        If none of the categories are present in their response, provide 0's for all key values in your JSON. \\\n",
    "        Numbered categories: \"{categories_str}\".\"\"\"\n",
    "\n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=user_model,\n",
    "                messages=[\n",
    "                    {\n",
    "                      \"role\": \"system\",\n",
    "                      \"content\": f\"\"\"You are an expert in identifying themes and patterns in open-ended survey responses to the question, \"{survey_question}\". \\\n",
    "                      When given a survey response, you analyze it critically and thoroughly to identify user-provided categories present in the response.\"\"\"\n",
    "                    },\n",
    "                    {'role': 'user', \n",
    "                     'content': prompt}\n",
    "                ],\n",
    "                temperature=creativity\n",
    "            )\n",
    "\n",
    "            reply = response.choices[0].message.content\n",
    "            link1.append(reply)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "            link1.append(f\"Error processing input: {input}\")\n",
    "            \n",
    "        extracted_json = re.findall(r'```json\\n(\\{.*?\\})\\n```', reply, re.DOTALL)\n",
    "        extracted_json = extracted_json[0].replace('[', '').replace(']', '').replace('\\n', '').replace(\" \", '').replace(\"  \", '')\n",
    "        print(extracted_json)\n",
    "        extracted_jsons.append(extracted_json)\n",
    "            \n",
    "    normalized_data_list = []\n",
    "    error_lines = []\n",
    "    \n",
    "    for i, json_str in enumerate(extracted_jsons):\n",
    "        try:\n",
    "            parsed_obj = json.loads(json_str)\n",
    "            normalized_data_list.append(pd.json_normalize(parsed_obj))\n",
    "        except json.JSONDecodeError:\n",
    "            normalized_data_list.append(\"\"\"{\"1\":\"e\"}\"\"\")\n",
    "            continue\n",
    "\n",
    "    normalized_data = pd.concat(normalized_data_list, ignore_index=True)\n",
    "    \n",
    "    categorized_data = pd.DataFrame()\n",
    "    categorized_data['survey_response'] = survey_input\n",
    "    categorized_data['link1'] = link1\n",
    "    categorized_data['json'] = extracted_jsons\n",
    "    \n",
    "    categorized_data = pd.concat([categorized_data, normalized_data], axis=1)\n",
    "    \n",
    "    return categorized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7d2098",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "good = extract_categories_improved(survey_question, \n",
    "                            survey_input, \n",
    "                            user_model,\n",
    "                            creativity,\n",
    "                            user_categories)\n",
    "\n",
    "good.to_csv('data/a19i_good_categorization_5_cats.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0005c706",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_categories_cot(survey_question, \n",
    "                       survey_input,\n",
    "                       user_model,\n",
    "                       creativity,\n",
    "                       categories):\n",
    "    \n",
    "    client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\"))\n",
    "    \n",
    "    categories_str = \"\\n\".join(f\"{i + 1}. {cat}\" for i, cat in enumerate(categories))\n",
    "    cat_num = len(user_categories)\n",
    "    category_dict = {str(i+1): \"0\" for i in range(cat_num)}\n",
    "    example_JSON = json.dumps(category_dict, indent=4)\n",
    "    \n",
    "    link1 = []\n",
    "    extracted_jsons = []\n",
    "    \n",
    "    for response in survey_input:\n",
    "        prompt = f\"\"\"A survey respondent was asked, \"{survey_question}\" \\\n",
    "        Their response is here in triple backticks: ```{response}```. \\\n",
    "        First, thoruoughly extract all their answers to the question and be as specific as possible. \\\n",
    "        Second, take these reasons and select all of the following numbered categories they fall into: \\\n",
    "        \"{categories_str}\" \\\n",
    "        Third, form your response in proper JSON format. \\\n",
    "        The number belonging to the category shoulbe be the key and a 1 is the key value if the category is present. \\\n",
    "        If none of the categories are present in their response, provide 0's for all key values in your JSON.\"\"\"\n",
    "        print(prompt)\n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=user_model,\n",
    "                messages=[\n",
    "                    {\n",
    "                      \"role\": \"system\",\n",
    "                      \"content\": f\"\"\"You are an expert in identifying themes and patterns in open-ended survey responses to the question, \"{survey_question}\". \\\n",
    "                      When given a survey response, you analyze it critically and thoroughly to identify user-provided categories present in the response.\"\"\"\n",
    "                    },\n",
    "                    {'role': 'user', \n",
    "                     'content': prompt}\n",
    "                ],\n",
    "                temperature=creativity\n",
    "            )\n",
    "\n",
    "            reply = response.choices[0].message.content\n",
    "            link1.append(reply)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "            link1.append(f\"Error processing input: {input}\")\n",
    "            \n",
    "        extracted_json = re.findall(r'```json\\n(\\{.*?\\})\\n```', reply, re.DOTALL)\n",
    "        extracted_json = extracted_json[0].replace('[', '').replace(']', '').replace('\\n', '').replace(\" \", '').replace(\"  \", '')\n",
    "        print(extracted_json)\n",
    "        extracted_jsons.append(extracted_json)\n",
    "            \n",
    "    normalized_data_list = []\n",
    "    error_lines = []\n",
    "    \n",
    "    for i, json_str in enumerate(extracted_jsons):\n",
    "        try:\n",
    "            parsed_obj = json.loads(json_str)\n",
    "            normalized_data_list.append(pd.json_normalize(parsed_obj))\n",
    "        except json.JSONDecodeError:\n",
    "            normalized_data_list.append(\"\"\"{\"1\":\"e\"}\"\"\")\n",
    "            continue\n",
    "\n",
    "    normalized_data = pd.concat(normalized_data_list, ignore_index=True)\n",
    "    \n",
    "    categorized_data = pd.DataFrame()\n",
    "    categorized_data['survey_response'] = survey_input\n",
    "    categorized_data['link1'] = link1\n",
    "    categorized_data['json'] = extracted_jsons\n",
    "    \n",
    "    categorized_data = pd.concat([categorized_data, normalized_data], axis=1)\n",
    "    \n",
    "    return categorized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445db412",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cot = extract_categories_cot(survey_question, \n",
    "                            survey_input, \n",
    "                            user_model,\n",
    "                            creativity,\n",
    "                            user_categories)\n",
    "\n",
    "cot.to_csv('data/a19i_cot_categorization_5_cats.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1aaee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_categories_cove(survey_question, \n",
    "                       survey_input,\n",
    "                       user_model,\n",
    "                       creativity,\n",
    "                       categories):\n",
    "    \n",
    "    client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\"))\n",
    "    \n",
    "    categories_str = \"\\n\".join(f\"{i + 1}. {cat}\" for i, cat in enumerate(categories))\n",
    "    cat_num = len(categories)\n",
    "    category_dict = {str(i+1): \"0\" for i in range(cat_num)}\n",
    "    example_JSON = json.dumps(category_dict, indent=4)\n",
    "    \n",
    "    link1 = []\n",
    "    link2 = []\n",
    "    extracted_jsons = []\n",
    "    \n",
    "    for response in survey_input:\n",
    "        prompt = f\"\"\"Categorize this survey response \"{response}\" into all of the following reasons for moving and select all that apply: \\\n",
    "        {categories_str} \\\n",
    "        Provide your work in JSON format where the number belonging to each category is the key and a 1 if the category is present and a 0 if it is not present as key values.\"\"\"\n",
    "        try:\n",
    "            api_response = client.chat.completions.create(\n",
    "                model=user_model,\n",
    "                messages=[\n",
    "                    {'role': 'user', \n",
    "                     'content': prompt}\n",
    "                ],\n",
    "                temperature=creativity\n",
    "            )\n",
    "            reply = api_response.choices[0].message.content\n",
    "            print(reply)\n",
    "            link1.append(reply)\n",
    "\n",
    "            prompt2 = f\"\"\"Thank you for categorizing this survey response, \"{response}\". \\\n",
    "            Can you double check if there are any categories you might've missed or marked as being present incorrectly? \\\n",
    "            Here are the categories once again: {categories_str} \\\n",
    "            If there are any changes, please output a corrected JSON with the new categorization. \\\n",
    "            If there are no changes, please output the original JSON.\"\"\"\n",
    "            print(prompt2)\n",
    "            \n",
    "\n",
    "            api_response2 = client.chat.completions.create(\n",
    "                model=user_model,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": f\"\"\"You just categorized an answer to the question, \"{survey_question}\". You are revisiting your initial categorizations for accuracy. Here's what you initially identified: {reply}\"\"\"}, \n",
    "                    {'role':'assistant', 'content': reply},\n",
    "                    {'role': 'user', 'content': prompt2}\n",
    "                ],\n",
    "                temperature=.25,\n",
    "            )\n",
    "\n",
    "            reply2 = api_response2.choices[0].message.content\n",
    "            link2.append(reply2)\n",
    "            \n",
    "            extracted_json = re.findall(r'```json\\n(\\{.*?\\})\\n```', reply2, re.DOTALL)\n",
    "            extracted_json = extracted_json[0].replace('[', '').replace(']', '').replace('\\n', '').replace(\" \", '').replace(\"  \", '')\n",
    "            print(extracted_json)\n",
    "            extracted_jsons.append(extracted_json)\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "            link1.append(f\"Error processing input: {survey_input}\")\n",
    "            link2.append(f\"Error processing response: {reply}\")\n",
    "            \n",
    "    normalized_data_list = []\n",
    "    error_lines = []\n",
    "    \n",
    "    for i, json_str in enumerate(extracted_jsons):\n",
    "        try:\n",
    "            parsed_obj = json.loads(json_str)\n",
    "            normalized_data_list.append(pd.json_normalize(parsed_obj))\n",
    "        except json.JSONDecodeError:\n",
    "            normalized_data_list.append(\"\"\"{\"1\":\"e\"}\"\"\")\n",
    "            continue\n",
    "\n",
    "    normalized_data = pd.concat(normalized_data_list, ignore_index=True)\n",
    "    \n",
    "    categorized_data = pd.DataFrame()\n",
    "    categorized_data['survey_response'] = survey_input\n",
    "    categorized_data['link1'] = link1\n",
    "    categorized_data['link2'] = link2\n",
    "    categorized_data['json'] = extracted_jsons\n",
    "    \n",
    "    categorized_data = pd.concat([categorized_data, normalized_data], axis=1)\n",
    "    \n",
    "    return categorized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba270ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "creativity = .0\n",
    "\n",
    "cove = extract_categories_cove(survey_question, \n",
    "                            survey_input, \n",
    "                            user_model,\n",
    "                            creativity,\n",
    "                            user_categories)\n",
    "\n",
    "cove.to_csv('data/a19i_cove_categorization_5_cats.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5e5fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_categories_1s(survey_question, \n",
    "                       survey_input,\n",
    "                       user_model,\n",
    "                       creativity,\n",
    "                       categories):\n",
    "    \n",
    "    client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\"))\n",
    "    \n",
    "    categories_str = \"\\n\".join(f\"{i + 1}. {cat}\" for i, cat in enumerate(categories))\n",
    "    cat_num = len(user_categories)\n",
    "    category_dict = {str(i+1): \"0\" for i in range(cat_num)}\n",
    "    example_categorization = \"\"\"{\"1\":\"0\",\"2\":\"0\",\"3\":\"0\",\"4\":\"1\",\"5\":\"1\"}\"\"\"\n",
    "    example_response = \"opportunity to rent a larger place for the same amount of money. opportunity to rent from family at below market and be near family (aunt).\"\n",
    "    link1 = []\n",
    "    extracted_jsons = []\n",
    "    \n",
    "    for response in survey_input:\n",
    "        prompt = f\"\"\"Categorize this survey response \"{response}\" into all of the following reasons for moving and select all that apply: \\\n",
    "        {categories_str} \\\n",
    "        Provide your work in JSON format where the number belonging to each category is the key and a 1 if the category is present and a 0 if it is not present as key values. \\\n",
    "        Here's an example of a correct categorization. \\\n",
    "        Example survey response: {example_response}. \\\n",
    "        Example categorization: {example_categorization}.\"\"\"\n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=user_model,\n",
    "                messages=[\n",
    "                    {'role': 'user', 'content': prompt}\n",
    "                ],\n",
    "                temperature=creativity\n",
    "            )\n",
    "\n",
    "            reply = response.choices[0].message.content\n",
    "            link1.append(reply)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "            link1.append(f\"Error processing input: {input}\")\n",
    "           \n",
    "        extracted_json = re.findall(r'```json\\n(\\{.*?\\})\\n```', reply, re.DOTALL)\n",
    "            \n",
    "        if extracted_json:\n",
    "            cleaned_json = extracted_json[0].replace('[', '').replace(']', '').replace('\\n', '').replace(\" \", '').replace(\"  \", '')\n",
    "            extracted_jsons.append(cleaned_json)\n",
    "            print(cleaned_json)\n",
    "        else:\n",
    "            error_message = \"error in processing JSON\"\n",
    "            extracted_jsons.append(error_message)\n",
    "            print(error_message)\n",
    "            \n",
    "    normalized_data_list = []\n",
    "    error_lines = []\n",
    "    \n",
    "    for i, json_str in enumerate(extracted_jsons):\n",
    "        try:\n",
    "            parsed_obj = json.loads(json_str)\n",
    "            normalized_data_list.append(pd.json_normalize(parsed_obj))\n",
    "        except json.JSONDecodeError:\n",
    "            normalized_data_list.append(\"\"\"{\"1\":\"e\"}\"\"\")\n",
    "            continue\n",
    "\n",
    "    normalized_data = pd.concat(normalized_data_list, ignore_index=True)\n",
    "    \n",
    "    categorized_data = pd.DataFrame()\n",
    "    categorized_data['survey_response'] = survey_input\n",
    "    categorized_data['link1'] = link1\n",
    "    categorized_data['json'] = extracted_jsons\n",
    "    \n",
    "    categorized_data = pd.concat([categorized_data, normalized_data], axis=1)\n",
    "    \n",
    "    return categorized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f75a914",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "oneshot = extract_categories_1s(survey_question, \n",
    "                            survey_input, \n",
    "                            user_model,\n",
    "                            creativity,\n",
    "                            user_categories)\n",
    "\n",
    "oneshot.to_csv('data/a19i_1s_categorization_5_cats.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b29e8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_categories_fs(survey_question, \n",
    "                       survey_input,\n",
    "                       user_model,\n",
    "                       creativity,\n",
    "                       categories):\n",
    "    \n",
    "    client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\"))\n",
    "    \n",
    "    categories_str = \"\\n\".join(f\"{i + 1}. {cat}\" for i, cat in enumerate(categories))\n",
    "    cat_num = len(user_categories)\n",
    "    category_dict = {str(i+1): \"0\" for i in range(cat_num)}\n",
    "    example_response = \"the rent was increasing; they wanted to renew the rent $400 extra, a month to re-lease. made sense regarding my career. and i wanted a backyard for my dog.\"\n",
    "    example_categorization = \"\"\"{\"1\":\"0\",\"2\":\"1\",\"3\":\"0\",\"4\":\"1\",\"5\":\"0\"}\"\"\"\n",
    "    example_response2 = \"lease ended at my old apartment and i wanted to move back to my parents house to pay off more of my student loans\"\n",
    "    example_categorization2 = \"\"\"{\"1\":\"0\",\"2\":\"0\",\"3\":\"0\",\"4\":\"1\",\"5\":\"1\"}\"\"\"\n",
    "    example_response3 = \"there was a fire in building where i previously lived; all tenants displaced, we had to find other housing. after the fire i stayed 3 days with a friend, then 2 months in a hotel, then began living in my current apartment in same city. move was not by choice, was circumstantial.\"\n",
    "    example_categorization3 = \"\"\"{\"1\":\"0\",\"2\":\"0\",\"3\":\"0\",\"4\":\"0\",\"5\":\"0\"}\"\"\"\n",
    "    \n",
    "    link1 = []\n",
    "    extracted_jsons = []\n",
    "    \n",
    "    for response in survey_input:\n",
    "        prompt = f\"\"\"Categorize this survey response \"{response}\" into all of the following reasons for moving and select all that apply: \\\n",
    "        {categories_str} \\\n",
    "        Provide your work in JSON format where the number belonging to each category is the key and a 1 if the category is present and a 0 if it is not present as key values. \\\n",
    "        Here are three examples of a correct categorization. \\\n",
    "        Example survey response 1: {example_response}. \\\n",
    "        Example categorization 1: {example_categorization}. \\\n",
    "        Example survey response 2: {example_response2}. \\\n",
    "        Example categorization 2: {example_categorization2}. \\\n",
    "        Example survey response 3: {example_response3}. \\\n",
    "        Example categorization 3: {example_categorization3}.\"\"\"\n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=user_model,\n",
    "                messages=[\n",
    "                    {'role': 'user', 'content': prompt}\n",
    "                ],\n",
    "                temperature=creativity\n",
    "            )\n",
    "\n",
    "            reply = response.choices[0].message.content\n",
    "            link1.append(reply)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "            link1.append(f\"Error processing input: {input}\")\n",
    "            \n",
    "        extracted_json = re.findall(r'```json\\n(\\{.*?\\})\\n```', reply, re.DOTALL)\n",
    "            \n",
    "        if extracted_json:\n",
    "            cleaned_json = extracted_json[0].replace('[', '').replace(']', '').replace('\\n', '').replace(\" \", '').replace(\"  \", '')\n",
    "            extracted_jsons.append(cleaned_json)\n",
    "            print(cleaned_json)\n",
    "        else:\n",
    "            error_message = \"\"\"{\"1\":\"e\"}\"\"\"\n",
    "            extracted_jsons.append(error_message)\n",
    "            print(error_message)\n",
    "            \n",
    "    normalized_data_list = []\n",
    "    error_lines = []\n",
    "    \n",
    "    for i, json_str in enumerate(extracted_jsons):\n",
    "        try:\n",
    "            parsed_obj = json.loads(json_str)\n",
    "            normalized_data_list.append(pd.json_normalize(parsed_obj))\n",
    "        except json.JSONDecodeError:\n",
    "            normalized_data_list.append(\"\"\"{\"1\":\"e\"}\"\"\")\n",
    "            continue\n",
    "\n",
    "    normalized_data = pd.concat(normalized_data_list, ignore_index=True)\n",
    "    \n",
    "    categorized_data = pd.DataFrame()\n",
    "    categorized_data['survey_response'] = survey_input\n",
    "    categorized_data['link1'] = link1\n",
    "    categorized_data['json'] = extracted_jsons\n",
    "    \n",
    "    categorized_data = pd.concat([categorized_data, normalized_data], axis=1)\n",
    "    \n",
    "    return categorized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8dccc6c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fewshot = extract_categories_fs(survey_question, \n",
    "                            survey_input, \n",
    "                            user_model,\n",
    "                            creativity,\n",
    "                            user_categories)\n",
    "\n",
    "fewshot.to_csv('data/a19i_fs_categorization_5_cats.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cb51e88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_categories_cot_1s(survey_question, \n",
    "                       survey_input,\n",
    "                       user_model,\n",
    "                       creativity,\n",
    "                       categories):\n",
    "    \n",
    "    client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\"))\n",
    "    \n",
    "    categories_str = \"\\n\".join(f\"{i + 1}. {cat}\" for i, cat in enumerate(categories))\n",
    "    cat_num = len(user_categories)\n",
    "    category_dict = {str(i+1): 0 for i in range(cat_num)}\n",
    "    example_JSON = json.dumps(category_dict, indent=4)\n",
    "    example_categorization = \"\"\"{\"1\":0,\"2\":0,\"3\":0,\"4\":1,\"5\":1}\"\"\"\n",
    "    #1. going out with coworkers, 2. board games (cultural-hobby), 3. activities in the city (broader participation)\n",
    "    example_response = \"opportunity to rent a larger place for the same amount of money. opportunity to rent from family at below market and be near family (aunt).\"\n",
    "    link1 = []\n",
    "    extracted_jsons = []\n",
    "    \n",
    "    for response in survey_input:\n",
    "        prompt = f\"\"\"A survey respondent was asked, \"{survey_question}\" \\\n",
    "        Their response is here in triple backticks: ```{response}```. \\\n",
    "        First, thoruoughly extract all their answers to the question and be as specific as possible. \\\n",
    "        Second, take these reasons and select all of the following numbered categories they fall into: \\\n",
    "        \"{categories_str}\" \\\n",
    "        Here's an example of a correct categorization. \\\n",
    "        Example survey response: {example_response} \\\n",
    "        Example categorization: {example_categorization}. \\\n",
    "        If none of the categories are present in their response, provide 0's for all key values in your JSON.\"\"\"\n",
    "        print(prompt)\n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=user_model,\n",
    "                messages=[\n",
    "                    {\n",
    "                      \"role\": \"system\",\n",
    "                      \"content\": f\"\"\"You are an expert in identifying themes and patterns in open-ended survey responses to the question, \"{survey_question}\". \\\n",
    "                      When given a survey response, you analyze it critically and thoroughly to identify user-provided categories present in the response.\"\"\"\n",
    "                    },\n",
    "                    {'role': 'user', \n",
    "                     'content': prompt}\n",
    "                ],\n",
    "                temperature=creativity\n",
    "            )\n",
    "\n",
    "            reply = response.choices[0].message.content\n",
    "            link1.append(reply)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "            link1.append(f\"Error processing input: {input}\")\n",
    "            \n",
    "        extracted_json = re.findall(r'(\\{.*?\\})\\n', reply, re.DOTALL)\n",
    "        print(extracted_json)\n",
    "            \n",
    "        if extracted_json:\n",
    "            cleaned_json = extracted_json[0].replace('[', '').replace(']', '').replace('\\n', '').replace(\" \", '').replace(\"  \", '')\n",
    "            extracted_jsons.append(cleaned_json)\n",
    "            print(cleaned_json)\n",
    "        else:\n",
    "            error_message = \"\"\"{\"1\":\"e\"}\"\"\"\n",
    "            extracted_jsons.append(error_message)\n",
    "            print(error_message)\n",
    "            \n",
    "    normalized_data_list = []\n",
    "    error_lines = []\n",
    "    \n",
    "    for i, json_str in enumerate(extracted_jsons):\n",
    "        try:\n",
    "            # Attempt to parse the JSON string\n",
    "            parsed_obj = json.loads(json_str)\n",
    "            # Convert the parsed object to a DataFrame and append\n",
    "            normalized_data_list.append(pd.json_normalize(parsed_obj))\n",
    "        except json.JSONDecodeError:\n",
    "            # Define a default JSON object as a dictionary\n",
    "            default_json_obj = {\"1\": \"j\"}\n",
    "            # Convert the default object to a DataFrame and append\n",
    "            normalized_data_list.append(pd.json_normalize(default_json_obj))\n",
    "\n",
    "    normalized_data = pd.concat(normalized_data_list, ignore_index=True)\n",
    "    \n",
    "    categorized_data = pd.DataFrame()\n",
    "    categorized_data['survey_response'] = survey_input\n",
    "    categorized_data['link1'] = link1\n",
    "    categorized_data['json'] = extracted_jsons\n",
    "    \n",
    "    categorized_data = pd.concat([categorized_data, normalized_data], axis=1)\n",
    "    \n",
    "    return categorized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9c675d6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A survey respondent was asked, \"Why did you move?\"         Their response is here in triple backticks: ```relocated back to east coast - closer to my sons```.         First, thoruoughly extract all their answers to the question and be as specific as possible.         Second, take these reasons and select all of the following numbered categories they fall into:         \"1. to start or continue living with with a partner/spouse\n",
      "2. related to the person's job, school or career, including transfers, retirement, a new job, or wanting to be closer to work\n",
      "3. related to their partner's job, school or career, such as transfers, retirement, a new job, wanting to be closer to work\n",
      "4. financial reasons, such as increases in rent, affordability of the current housing expenses, pay raises\n",
      "5. related to family members for various reasons, such as providing support, facilitating care, a child's schooling needs, or a new baby\"         Here's an example of a correct categorization.         Example survey response: opportunity to rent a larger place for the same amount of money. opportunity to rent from family at below market and be near family (aunt).         Example categorization: {\"1\":0,\"2\":0,\"3\":0,\"4\":1,\"5\":1}.         If none of the categories are present in their response, provide 0's for all key values in your JSON.\n",
      "['{\"1\":0,\"2\":0,\"3\":0,\"4\":0,\"5\":1}']\n",
      "{\"1\":0,\"2\":0,\"3\":0,\"4\":0,\"5\":1}\n",
      "A survey respondent was asked, \"Why did you move?\"         Their response is here in triple backticks: ```move in together with my partner```.         First, thoruoughly extract all their answers to the question and be as specific as possible.         Second, take these reasons and select all of the following numbered categories they fall into:         \"1. to start or continue living with with a partner/spouse\n",
      "2. related to the person's job, school or career, including transfers, retirement, a new job, or wanting to be closer to work\n",
      "3. related to their partner's job, school or career, such as transfers, retirement, a new job, wanting to be closer to work\n",
      "4. financial reasons, such as increases in rent, affordability of the current housing expenses, pay raises\n",
      "5. related to family members for various reasons, such as providing support, facilitating care, a child's schooling needs, or a new baby\"         Here's an example of a correct categorization.         Example survey response: opportunity to rent a larger place for the same amount of money. opportunity to rent from family at below market and be near family (aunt).         Example categorization: {\"1\":0,\"2\":0,\"3\":0,\"4\":1,\"5\":1}.         If none of the categories are present in their response, provide 0's for all key values in your JSON.\n",
      "[]\n",
      "{\"1\":\"e\"}\n",
      "A survey respondent was asked, \"Why did you move?\"         Their response is here in triple backticks: ```out of living with my friends, and into living with my boy friend```.         First, thoruoughly extract all their answers to the question and be as specific as possible.         Second, take these reasons and select all of the following numbered categories they fall into:         \"1. to start or continue living with with a partner/spouse\n",
      "2. related to the person's job, school or career, including transfers, retirement, a new job, or wanting to be closer to work\n",
      "3. related to their partner's job, school or career, such as transfers, retirement, a new job, wanting to be closer to work\n",
      "4. financial reasons, such as increases in rent, affordability of the current housing expenses, pay raises\n",
      "5. related to family members for various reasons, such as providing support, facilitating care, a child's schooling needs, or a new baby\"         Here's an example of a correct categorization.         Example survey response: opportunity to rent a larger place for the same amount of money. opportunity to rent from family at below market and be near family (aunt).         Example categorization: {\"1\":0,\"2\":0,\"3\":0,\"4\":1,\"5\":1}.         If none of the categories are present in their response, provide 0's for all key values in your JSON.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m cot1s \u001b[38;5;241m=\u001b[39m \u001b[43mextract_categories_cot_1s\u001b[49m\u001b[43m(\u001b[49m\u001b[43msurvey_question\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                            \u001b[49m\u001b[43msurvey_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                            \u001b[49m\u001b[43muser_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mcreativity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                            \u001b[49m\u001b[43muser_categories\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m cot1s\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/a19i/a19i_cot1s_categorization_5_cats.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[11], line 31\u001b[0m, in \u001b[0;36mextract_categories_cot_1s\u001b[0;34m(survey_question, survey_input, user_model, creativity, categories)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28mprint\u001b[39m(prompt)\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 31\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m              \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msystem\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m              \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\"\"\u001b[39;49m\u001b[38;5;124;43mYou are an expert in identifying themes and patterns in open-ended survey responses to the question, \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43msurvey_question\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m. \u001b[39;49m\u001b[38;5;130;43;01m\\\u001b[39;49;00m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;124;43m              When given a survey response, you analyze it critically and thoroughly to identify user-provided categories present in the response.\u001b[39;49m\u001b[38;5;124;43m\"\"\"\u001b[39;49m\n\u001b[1;32m     38\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m             \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m        \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcreativity\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m     reply \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent\n\u001b[1;32m     46\u001b[0m     link1\u001b[38;5;241m.\u001b[39mappend(reply)\n",
      "File \u001b[0;32m~/anaconda3/envs/AI/lib/python3.8/site-packages/openai/_utils/_utils.py:271\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    269\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    270\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 271\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/AI/lib/python3.8/site-packages/openai/resources/chat/completions.py:659\u001b[0m, in \u001b[0;36mCompletions.create\u001b[0;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, logprobs, max_tokens, n, presence_penalty, response_format, seed, stop, stream, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    608\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    609\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    610\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    657\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    658\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[0;32m--> 659\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    660\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    661\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    662\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    663\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    664\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    665\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    666\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    667\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    680\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    682\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    683\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    684\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    685\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    686\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    687\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    688\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    689\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    690\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    691\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    692\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/AI/lib/python3.8/site-packages/openai/_base_client.py:1180\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1166\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1167\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1168\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1175\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1176\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1177\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1178\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1179\u001b[0m     )\n\u001b[0;32m-> 1180\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/anaconda3/envs/AI/lib/python3.8/site-packages/openai/_base_client.py:869\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    860\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[1;32m    861\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    862\u001b[0m     cast_to: Type[ResponseT],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    867\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    868\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m--> 869\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    871\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    872\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    873\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m        \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/AI/lib/python3.8/site-packages/openai/_base_client.py:898\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    895\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauth\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcustom_auth\n\u001b[1;32m    897\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 898\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    899\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    900\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_should_stream_response_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    901\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    902\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    903\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mTimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    904\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncountered httpx.TimeoutException\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/AI/lib/python3.8/site-packages/httpx/_client.py:915\u001b[0m, in \u001b[0;36mClient.send\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m    907\u001b[0m follow_redirects \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    908\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfollow_redirects\n\u001b[1;32m    909\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(follow_redirects, UseClientDefault)\n\u001b[1;32m    910\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m follow_redirects\n\u001b[1;32m    911\u001b[0m )\n\u001b[1;32m    913\u001b[0m auth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request_auth(request, auth)\n\u001b[0;32m--> 915\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    916\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    917\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    918\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    919\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    920\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    921\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    922\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "File \u001b[0;32m~/anaconda3/envs/AI/lib/python3.8/site-packages/httpx/_client.py:943\u001b[0m, in \u001b[0;36mClient._send_handling_auth\u001b[0;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[1;32m    940\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[1;32m    942\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 943\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    944\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    945\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    946\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    947\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    948\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/AI/lib/python3.8/site-packages/httpx/_client.py:980\u001b[0m, in \u001b[0;36mClient._send_handling_redirects\u001b[0;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[1;32m    977\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequest\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    978\u001b[0m     hook(request)\n\u001b[0;32m--> 980\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    981\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    982\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[0;32m~/anaconda3/envs/AI/lib/python3.8/site-packages/httpx/_client.py:1016\u001b[0m, in \u001b[0;36mClient._send_single_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m   1011\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1012\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1013\u001b[0m     )\n\u001b[1;32m   1015\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39mrequest):\n\u001b[0;32m-> 1016\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mtransport\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1018\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, SyncByteStream)\n\u001b[1;32m   1020\u001b[0m response\u001b[38;5;241m.\u001b[39mrequest \u001b[38;5;241m=\u001b[39m request\n",
      "File \u001b[0;32m~/anaconda3/envs/AI/lib/python3.8/site-packages/httpx/_transports/default.py:231\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    218\u001b[0m req \u001b[38;5;241m=\u001b[39m httpcore\u001b[38;5;241m.\u001b[39mRequest(\n\u001b[1;32m    219\u001b[0m     method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[1;32m    220\u001b[0m     url\u001b[38;5;241m=\u001b[39mhttpcore\u001b[38;5;241m.\u001b[39mURL(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    228\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    229\u001b[0m )\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[0;32m--> 231\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[1;32m    236\u001b[0m     status_code\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mstatus,\n\u001b[1;32m    237\u001b[0m     headers\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[1;32m    238\u001b[0m     stream\u001b[38;5;241m=\u001b[39mResponseStream(resp\u001b[38;5;241m.\u001b[39mstream),\n\u001b[1;32m    239\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    240\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/AI/lib/python3.8/site-packages/httpcore/_sync/connection_pool.py:268\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ShieldCancellation():\n\u001b[1;32m    267\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresponse_closed(status)\n\u001b[0;32m--> 268\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[1;32m    269\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    270\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/AI/lib/python3.8/site-packages/httpcore/_sync/connection_pool.py:251\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 251\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[1;32m    253\u001b[0m     \u001b[38;5;66;03m# The ConnectionNotAvailable exception is a special case, that\u001b[39;00m\n\u001b[1;32m    254\u001b[0m     \u001b[38;5;66;03m# indicates we need to retry the request on a new connection.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[38;5;66;03m# might end up as an HTTP/2 connection, but which actually ends\u001b[39;00m\n\u001b[1;32m    259\u001b[0m     \u001b[38;5;66;03m# up as HTTP/1.1.\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pool_lock:\n\u001b[1;32m    261\u001b[0m         \u001b[38;5;66;03m# Maintain our position in the request queue, but reset the\u001b[39;00m\n\u001b[1;32m    262\u001b[0m         \u001b[38;5;66;03m# status so that the request becomes queued again.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/AI/lib/python3.8/site-packages/httpcore/_sync/connection.py:103\u001b[0m, in \u001b[0;36mHTTPConnection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection\u001b[38;5;241m.\u001b[39mis_available():\n\u001b[1;32m    101\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ConnectionNotAvailable()\n\u001b[0;32m--> 103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/AI/lib/python3.8/site-packages/httpcore/_sync/http11.py:133\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_closed\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m    132\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_closed()\n\u001b[0;32m--> 133\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[0;32m~/anaconda3/envs/AI/lib/python3.8/site-packages/httpcore/_sync/http11.py:111\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreceive_response_headers\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request, kwargs\n\u001b[1;32m    105\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m    106\u001b[0m     (\n\u001b[1;32m    107\u001b[0m         http_version,\n\u001b[1;32m    108\u001b[0m         status,\n\u001b[1;32m    109\u001b[0m         reason_phrase,\n\u001b[1;32m    110\u001b[0m         headers,\n\u001b[0;32m--> 111\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_response_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    112\u001b[0m     trace\u001b[38;5;241m.\u001b[39mreturn_value \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    113\u001b[0m         http_version,\n\u001b[1;32m    114\u001b[0m         status,\n\u001b[1;32m    115\u001b[0m         reason_phrase,\n\u001b[1;32m    116\u001b[0m         headers,\n\u001b[1;32m    117\u001b[0m     )\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[1;32m    120\u001b[0m     status\u001b[38;5;241m=\u001b[39mstatus,\n\u001b[1;32m    121\u001b[0m     headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    127\u001b[0m     },\n\u001b[1;32m    128\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/AI/lib/python3.8/site-packages/httpcore/_sync/http11.py:176\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_response_headers\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    173\u001b[0m timeout \u001b[38;5;241m=\u001b[39m timeouts\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 176\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    177\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11\u001b[38;5;241m.\u001b[39mResponse):\n\u001b[1;32m    178\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/AI/lib/python3.8/site-packages/httpcore/_sync/http11.py:212\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_event\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    209\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mnext_event()\n\u001b[1;32m    211\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11\u001b[38;5;241m.\u001b[39mNEED_DATA:\n\u001b[0;32m--> 212\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_network_stream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    213\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[1;32m    224\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;241m==\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mtheir_state \u001b[38;5;241m==\u001b[39m h11\u001b[38;5;241m.\u001b[39mSEND_RESPONSE:\n",
      "File \u001b[0;32m~/anaconda3/envs/AI/lib/python3.8/site-packages/httpcore/_backends/sync.py:126\u001b[0m, in \u001b[0;36mSyncStream.read\u001b[0;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39msettimeout(timeout)\n\u001b[0;32m--> 126\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/AI/lib/python3.8/ssl.py:1259\u001b[0m, in \u001b[0;36mSSLSocket.recv\u001b[0;34m(self, buflen, flags)\u001b[0m\n\u001b[1;32m   1255\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1256\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1257\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1258\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1259\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuflen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1260\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1261\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv(buflen, flags)\n",
      "File \u001b[0;32m~/anaconda3/envs/AI/lib/python3.8/ssl.py:1134\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[1;32m   1133\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1134\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1135\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SSLError \u001b[38;5;28;01mas\u001b[39;00m x:\n\u001b[1;32m   1136\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m SSL_ERROR_EOF \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msuppress_ragged_eofs:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cot1s = extract_categories_cot_1s(survey_question, \n",
    "                            survey_input, \n",
    "                            user_model,\n",
    "                            creativity,\n",
    "                            user_categories)\n",
    "\n",
    "cot1s.to_csv('data/a19i/a19i_cot1s_categorization_5_cats.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff756da1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "“AI”",
   "language": "python",
   "name": "ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
