{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78c77629",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.prompts.prompt import PromptTemplate #where we change the AI \"personality\"\n",
    "from dotenv import load_dotenv, find_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "129c22b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a25a7471",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "#openai.api_key = os.getenv(\"api.txt\")\n",
    "COMPLETIONS_MODEL = \"text-davinci-002\"\n",
    "BETTER_COMPLETIONS_MODEL = \"text-davinci-003\" #for my purposes, this is better\n",
    "LONG_MODEL = \"gpt-3.5-turbo-16k\"\n",
    "REGULAR_MODEL = \"gpt-3.5-turbo\"\n",
    "GPT_4 = \"gpt-4-1106-preview\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b96d96b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/chrissoria/Documents/Research/Categorization_AI_experiments\n"
     ]
    }
   ],
   "source": [
    "os.chdir('/Users/chrissoria/Documents/Research/Categorization_AI_experiments')\n",
    "current_directory = os.getcwd()\n",
    "print(current_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a7b7a15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a19i</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>relocated back to east coast - closer to my sons</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>move in together with my partner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>out of living with my friends, and into living...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                a19i\n",
       "0   relocated back to east coast - closer to my sons\n",
       "1                   move in together with my partner\n",
       "2  out of living with my friends, and into living..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "survey_participant_input = \"a19i\" #enter column name here\n",
    "\n",
    "UCNets = pd.read_excel(\"/Users/chrissoria/Documents/Research/UCNets_Classification/data/Raw_Cond_for_Coding_all_waves.xlsx\", engine='openpyxl',sheet_name=\"JOINT_DATA\",usecols=[survey_participant_input])\n",
    "UCNets = UCNets[survey_participant_input].dropna().unique()  # Drop NaN values and get unique elements\n",
    "\n",
    "survey_participant_responses = '; '.join(str(item) for item in UCNets) #what we will feed to the model\n",
    "\n",
    "UCNets = pd.DataFrame(UCNets, columns=[survey_participant_input])\n",
    "UCNets[survey_participant_input] = UCNets[survey_participant_input].astype(str).str.lower()\n",
    "UCNets[survey_participant_input] = UCNets[survey_participant_input].str.strip()\n",
    "UCNets = UCNets[UCNets[survey_participant_input] != ''].reset_index(drop=True) #trimming all empty rows\n",
    "\n",
    "UCNets = UCNets.iloc[:3]\n",
    "\n",
    "UCNets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b77e00c",
   "metadata": {},
   "source": [
    "Here, I'm trying to \"force\" the model to \"think\" in steps by first A. trying to process the response into its own words and B. having it interact with that object. That is, instead of all steps being given at once, I'm having it think in steps. \n",
    "\n",
    "This time, I will have it think in a \"chain,\" where I will have it output a response and then feed that response back to it in a seperate prompt. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae55712c",
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_question = \"Why did you move?\"\n",
    "survey_input = UCNets['a19i']\n",
    "\n",
    "creativity = .0\n",
    "\n",
    "user_categories = [\"to start or continue living with with a partner/spouse\",\n",
    "                   \"related to the person's job, school or career, including transfers, retirement, a new job, or wanting to be closer to work\",\n",
    "                   \"related to their partner's job, school or career, such as transfers, retirement, a new job, wanting to be closer to work\",\n",
    "                   \"financial reasons, such as increases in rent, affordability of the current housing expenses, pay raises\",\n",
    "                   \"related to family members for various reasons, such as providing support, facilitating care, a child's schooling needs, or a new baby\"]\n",
    "\n",
    "user_model = 'gpt-4-1106-preview'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "100c17dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_categories_fs(survey_question, \n",
    "                       survey_input,\n",
    "                       user_model,\n",
    "                       creativity,\n",
    "                       categories):\n",
    "    \n",
    "    client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\"))\n",
    "    \n",
    "    categories_str = \"\\n\".join(f\"{i + 1}. {cat}\" for i, cat in enumerate(categories))\n",
    "    cat_num = len(user_categories)\n",
    "    category_dict = {str(i+1): \"0\" for i in range(cat_num)}\n",
    "    example_response = \"the rent was increasing; they wanted to renew the rent $400 extra, a month to re-lease. made sense regarding my career. and i wanted a backyard for my dog.\"\n",
    "    example_categorization = \"\"\"{\"1\":\"0\",\"2\":\"1\",\"3\":\"0\",\"4\":\"1\",\"5\":\"0\"}\"\"\"\n",
    "    example_response2 = \"lease ended at my old apartment and i wanted to move back to my parents house to pay off more of my student loans\"\n",
    "    example_categorization2 = \"\"\"{\"1\":\"0\",\"2\":\"0\",\"3\":\"0\",\"4\":\"1\",\"5\":\"1\"}\"\"\"\n",
    "    example_response3 = \"there was a fire in building where i previously lived; all tenants displaced, we had to find other housing. after the fire i stayed 3 days with a friend, then 2 months in a hotel, then began living in my current apartment in same city. move was not by choice, was circumstantial.\"\n",
    "    example_categorization3 = \"\"\"{\"1\":\"0\",\"2\":\"0\",\"3\":\"0\",\"4\":\"0\",\"5\":\"0\"}\"\"\"\n",
    "    \n",
    "    link1 = []\n",
    "    extracted_jsons = []\n",
    "    \n",
    "    for response in survey_input:\n",
    "        prompt = f\"\"\"Categorize this survey response \"{response}\" into all of the following reasons for moving and select all that apply: \\\n",
    "        {categories_str} \\\n",
    "        Provide your work in JSON format where the number belonging to each category is the key and a 1 if the category is present and a 0 if it is not present as key values. \\\n",
    "        Here are three examples of a correct categorization. \\\n",
    "        Example survey response 1: {example_response}. \\\n",
    "        Example categorization 1: {example_categorization}. \\\n",
    "        Example survey response 2: {example_response2}. \\\n",
    "        Example categorization 2: {example_categorization2}. \\\n",
    "        Example survey response 3: {example_response3}. \\\n",
    "        Example categorization 3: {example_categorization3}.\"\"\"\n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=user_model,\n",
    "                messages=[\n",
    "                    {'role': 'user', 'content': prompt}\n",
    "                ],\n",
    "                temperature=creativity\n",
    "            )\n",
    "\n",
    "            reply = response.choices[0].message.content\n",
    "            link1.append(reply)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "            link1.append(f\"Error processing input: {input}\")\n",
    "            \n",
    "        extracted_json = re.findall(r'```json\\n(\\{.*?\\})\\n```', reply, re.DOTALL)\n",
    "            \n",
    "        if extracted_json:\n",
    "            cleaned_json = extracted_json[0].replace('[', '').replace(']', '').replace('\\n', '').replace(\" \", '').replace(\"  \", '')\n",
    "            extracted_jsons.append(cleaned_json)\n",
    "            print(cleaned_json)\n",
    "        else:\n",
    "            error_message = \"\"\"{\"1\":\"e\"}\"\"\"\n",
    "            extracted_jsons.append(error_message)\n",
    "            print(error_message)\n",
    "            \n",
    "    normalized_data_list = []\n",
    "    error_lines = []\n",
    "    \n",
    "    for i, json_str in enumerate(extracted_jsons):\n",
    "        try:\n",
    "            parsed_obj = json.loads(json_str)\n",
    "            normalized_data_list.append(pd.json_normalize(parsed_obj))\n",
    "        except json.JSONDecodeError:\n",
    "            normalized_data_list.append(\"\"\"{\"1\":\"e\"}\"\"\")\n",
    "            continue\n",
    "            \n",
    "    normalized_data = pd.concat(normalized_data_list, ignore_index=True)\n",
    "    \n",
    "    categorized_data = pd.DataFrame()\n",
    "    categorized_data['survey_response'] = survey_input\n",
    "    categorized_data['link1'] = link1\n",
    "    categorized_data['json'] = extracted_jsons\n",
    "    \n",
    "    categorized_data = pd.concat([categorized_data, normalized_data], axis=1)\n",
    "    \n",
    "    return categorized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d47ccb37",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"1\":\"0\",\"2\":\"0\",\"3\":\"0\",\"4\":\"0\",\"5\":\"1\"}\n",
      "{\"1\":\"1\",\"2\":\"0\",\"3\":\"0\",\"4\":\"0\",\"5\":\"0\"}\n",
      "{\"1\":\"1\",\"2\":\"0\",\"3\":\"0\",\"4\":\"0\",\"5\":\"0\"}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survey_response</th>\n",
       "      <th>link1</th>\n",
       "      <th>json</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>relocated back to east coast - closer to my sons</td>\n",
       "      <td>Based on the survey response \"relocated back t...</td>\n",
       "      <td>{\"1\":\"0\",\"2\":\"0\",\"3\":\"0\",\"4\":\"0\",\"5\":\"1\"}</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>move in together with my partner</td>\n",
       "      <td>Based on the survey response \"move in together...</td>\n",
       "      <td>{\"1\":\"1\",\"2\":\"0\",\"3\":\"0\",\"4\":\"0\",\"5\":\"0\"}</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>out of living with my friends, and into living...</td>\n",
       "      <td>Based on the survey response \"out of living wi...</td>\n",
       "      <td>{\"1\":\"1\",\"2\":\"0\",\"3\":\"0\",\"4\":\"0\",\"5\":\"0\"}</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     survey_response  \\\n",
       "0   relocated back to east coast - closer to my sons   \n",
       "1                   move in together with my partner   \n",
       "2  out of living with my friends, and into living...   \n",
       "\n",
       "                                               link1  \\\n",
       "0  Based on the survey response \"relocated back t...   \n",
       "1  Based on the survey response \"move in together...   \n",
       "2  Based on the survey response \"out of living wi...   \n",
       "\n",
       "                                        json  1  2  3  4  5  \n",
       "0  {\"1\":\"0\",\"2\":\"0\",\"3\":\"0\",\"4\":\"0\",\"5\":\"1\"}  0  0  0  0  1  \n",
       "1  {\"1\":\"1\",\"2\":\"0\",\"3\":\"0\",\"4\":\"0\",\"5\":\"0\"}  1  0  0  0  0  \n",
       "2  {\"1\":\"1\",\"2\":\"0\",\"3\":\"0\",\"4\":\"0\",\"5\":\"0\"}  1  0  0  0  0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fewshot = extract_categories_fs(survey_question, \n",
    "                            survey_input, \n",
    "                            user_model,\n",
    "                            creativity,\n",
    "                            user_categories)\n",
    "\n",
    "fewshot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3dc4d8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "“AI”",
   "language": "python",
   "name": "ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
