{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78c77629",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.prompts.prompt import PromptTemplate #where we change the AI \"personality\"\n",
    "from dotenv import load_dotenv, find_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "129c22b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "API_KEY = os.environ.get(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a25a7471",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ChatOpenAI' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m REGULAR_MODEL \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt-3.5-turbo\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      8\u001b[0m GPT_4 \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt-4-1106-preview\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 10\u001b[0m chat \u001b[38;5;241m=\u001b[39m \u001b[43mChatOpenAI\u001b[49m(temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0\u001b[39m,\n\u001b[1;32m     11\u001b[0m                   openai_api_key \u001b[38;5;241m=\u001b[39m API_KEY,\n\u001b[1;32m     12\u001b[0m                   verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     13\u001b[0m                   model_name\u001b[38;5;241m=\u001b[39mGPT_4) \u001b[38;5;66;03m#depending on how big of a task\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m#below, we give the AI a \"personality\"\u001b[39;00m\n\u001b[1;32m     16\u001b[0m template \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124mThe following is a conversation between a human data scientist and an AI who specializes in data categorization. The AI is direct and provides concise responses. If the AI does not know the answer to a question, it truthfully says it does not know.\u001b[39m\n\u001b[1;32m     17\u001b[0m \n\u001b[1;32m     18\u001b[0m \u001b[38;5;124mCurrent conversation:\u001b[39m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;132;01m{history}\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;124mData Scientist: \u001b[39m\u001b[38;5;132;01m{input}\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;124mAI:\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ChatOpenAI' is not defined"
     ]
    }
   ],
   "source": [
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "#openai.api_key = os.getenv(\"api.txt\")\n",
    "COMPLETIONS_MODEL = \"text-davinci-002\"\n",
    "BETTER_COMPLETIONS_MODEL = \"text-davinci-003\" #for my purposes, this is better\n",
    "LONG_MODEL = \"gpt-3.5-turbo-16k\"\n",
    "REGULAR_MODEL = \"gpt-3.5-turbo\"\n",
    "GPT_4 = \"gpt-4-1106-preview\"\n",
    "\n",
    "chat = ChatOpenAI(temperature=0.0,\n",
    "                  openai_api_key = API_KEY,\n",
    "                  verbose=True,\n",
    "                  model_name=GPT_4) #depending on how big of a task\n",
    "\n",
    "#below, we give the AI a \"personality\"\n",
    "template = \"\"\"The following is a conversation between a human data scientist and an AI who specializes in data categorization. The AI is direct and provides concise responses. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
    "\n",
    "Current conversation:\n",
    "{history}\n",
    "Data Scientist: {input}\n",
    "AI:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96d96b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/Users/chrissoria/Documents/Research/Categorization_AI_experiments')\n",
    "current_directory = os.getcwd()\n",
    "print(current_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7b7a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_participant_input = \"a19i\" #enter column name here\n",
    "\n",
    "UCNets = pd.read_excel(\"/Users/chrissoria/Documents/Research/UCNets_Classification/data/Raw_Cond_for_Coding_all_waves.xlsx\", engine='openpyxl',sheet_name=\"JOINT_DATA\",usecols=[survey_participant_input])\n",
    "UCNets = UCNets[survey_participant_input].dropna().unique()  # Drop NaN values and get unique elements\n",
    "\n",
    "survey_participant_responses = '; '.join(str(item) for item in UCNets) #what we will feed to the model\n",
    "\n",
    "UCNets = pd.DataFrame(UCNets, columns=[survey_participant_input])\n",
    "UCNets[survey_participant_input] = UCNets[survey_participant_input].astype(str).str.lower()\n",
    "UCNets[survey_participant_input] = UCNets[survey_participant_input].str.strip()\n",
    "UCNets = UCNets[UCNets[survey_participant_input] != ''].reset_index(drop=True) #trimming all empty rows\n",
    "\n",
    "UCNets = UCNets.iloc[:200]\n",
    "\n",
    "UCNets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b77e00c",
   "metadata": {},
   "source": [
    "Here, I'm trying to \"force\" the model to \"think\" in steps by first A. trying to process the response into its own words and B. having it interact with that object. That is, instead of all steps being given at once, I'm having it think in steps. \n",
    "\n",
    "This time, I will have it think in a \"chain,\" where I will have it output a response and then feed that response back to it in a seperate prompt. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d645134f",
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_input = UCNets['a19i'][105] \n",
    "\n",
    "category = \"\"\"1. to start living with or to stay with partner/spouse. \\\n",
    "2. relationship change (divorce, breakup, etc). \\\n",
    "3. the respondent had a job or school or career change, including transferred and retired. \\\n",
    "4. the respondent's partner's job or school or career change, including transferred and retired. \\\n",
    "5. financial reasons (rent is too expensive, pay raise, etc).\n",
    "6. related to housing features, such as a bigger or smaller yard or house\"\"\"\n",
    "\n",
    "example_JSON = \"\"\"{ \\\n",
    "\"1\": \"0\", \\\n",
    "\"2\": \"1\", \\\n",
    "\"3\": \"0\", \\\n",
    "\"4\": 1, \\\n",
    "\"5\": \"0\", \\\n",
    "\"6\": \"0\"\n",
    "}\"\"\"\n",
    "\n",
    "caveat_1 =\"\"\"Be specific about how the move might've been because of a partner.\"\"\"\n",
    "\n",
    "template_string1 = \"\"\"A survey respondent was asked, \"Why did you move?\" \\\n",
    "They responded with: \"{OBJECT}\" \\\n",
    "First, filter out anything in this response that doesn't answer the question, \"Why did you move?\" \\\n",
    "Second, give me all of their reasons in a clear concise manner without any additional extrapolation. \\\n",
    "{CAVEAT}\n",
    "Format your response in a as few words as possible starting with the words, 'This respondent moved because...'\"\"\"\n",
    "\n",
    "prompt_template1 = ChatPromptTemplate.from_template(template_string1)\n",
    "prompt_template1.messages[0].prompt #this will show us our prompt template\n",
    "\n",
    "GPT_Responses1 = prompt_template1.format_messages(\n",
    "                    OBJECT=survey_input,\n",
    "                    CAVEAT=caveat_1)\n",
    "\n",
    "TEST1 = chat(GPT_Responses1)\n",
    "TEST1 = TEST1.content\n",
    "\n",
    "template_string2 = \"\"\"A survey respondent was asked, \"Why did you move?\" \\\n",
    "\"{OBJECT}\" \\\n",
    "Please determine how many of the following reasons for moving they provide from this list: \\\n",
    "{CATEGORY} \\\n",
    "Next, provide your answer as a 1 if yes and a 0 if no in JSON format \\\n",
    "Please do not provide any other text beyond the JSON. \\\n",
    "Here's an example of how you should format your response: \\\n",
    "{EXAMPLE}\"\"\"\n",
    "\n",
    "prompt_template2 = ChatPromptTemplate.from_template(template_string2)\n",
    "prompt_template2.messages[0].prompt #this will show us our prompt template\n",
    "\n",
    "GPT_Responses2 = prompt_template2.format_messages(\n",
    "                    OBJECT=TEST1,\n",
    "                    CATEGORY=category,\n",
    "                    EXAMPLE=example_JSON)\n",
    "\n",
    "TEST2 = chat(GPT_Responses2)\n",
    "TEST2 = TEST2.content\n",
    "print(TEST1)\n",
    "print(TEST2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef4c12d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(UCNets)):\n",
    "    survey_input = UCNets['a19i'][i]\n",
    "    response = prompt_template1.format_messages(\n",
    "                    OBJECT=survey_input,\n",
    "                    CAVEAT=caveat_1)\n",
    "\n",
    "    response = chat(response)\n",
    "    \n",
    "    # Assuming a successful attempt means a non-empty response\n",
    "    if response.content:\n",
    "        print(f\"Successful attempt for row number for chain 1: {i}\")\n",
    "    \n",
    "    UCNets.at[i, 'Key_Reasons'] = response.content\n",
    "    \n",
    "for i in range(len(UCNets)):\n",
    "    survey_input = UCNets['Key_Reasons'][i]\n",
    "    response = prompt_template2.format_messages(\n",
    "                    OBJECT=survey_input,\n",
    "                    CATEGORY=category,\n",
    "                    EXAMPLE=example_JSON)\n",
    "\n",
    "    response = chat(response)\n",
    "    \n",
    "    # Assuming a successful attempt means a non-empty response\n",
    "    if response.content:\n",
    "        print(f\"Successful attempt for row number for chain 2: {i}\")\n",
    "    \n",
    "    UCNets.at[i, 'JSON'] = response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc55fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "UCNets['JSON'] = UCNets['JSON'].astype(str)\n",
    "\n",
    "def remove_non_digits(text):\n",
    "    return re.sub(r'[^0-9]', '', text)\n",
    "\n",
    "def add_colon_before_comma(text):\n",
    "    new_text = \"\"\n",
    "    for i, char in enumerate(text):\n",
    "        if i < len(text) - 1 and text[i + 1] == ',':\n",
    "            new_text += ':' + char\n",
    "        else:\n",
    "            new_text += char\n",
    "    return new_text\n",
    "\n",
    "def add_colon_before_end(text):\n",
    "    if len(text) > 3:\n",
    "        return text[:-3] + ':\"' + text[-3:]\n",
    "    else:\n",
    "        return text\n",
    "\n",
    "# Apply the function to the 'JSON' column\n",
    "UCNets['JSON_clean'] = UCNets['JSON'].astype(str).apply(remove_non_digits)\n",
    "UCNets['JSON_clean'] = UCNets['JSON_clean'].apply(lambda x: x[-12:]) #= number of categories / 2\n",
    "UCNets['JSON_clean'] = UCNets['JSON_clean'].apply(lambda x: ','.join(x[i:i+2] for i in range(0, len(x), 2)))\n",
    "UCNets['JSON_clean'] = UCNets['JSON_clean'].apply(add_colon_before_comma)\n",
    "UCNets['JSON_clean'] = UCNets['JSON_clean'].apply(lambda x: \"{\" + x + \"}\")\n",
    "UCNets['JSON_clean'] = UCNets['JSON_clean'].apply(lambda x: '\"'.join(x[i:i+1] for i in range(0, len(x))))\n",
    "UCNets['JSON_clean'] = UCNets['JSON_clean'].apply(add_colon_before_end)\n",
    "\n",
    "\n",
    "UCNets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0565c3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_backticks(text):\n",
    "    return text.replace('```', '')\n",
    "\n",
    "def remove_json(text):\n",
    "    return text.replace('json', '')\n",
    "\n",
    "UCNets['JSON'] = UCNets['JSON'].apply(remove_backticks)\n",
    "UCNets['JSON'] = UCNets['JSON'].apply(remove_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125ce690",
   "metadata": {},
   "outputs": [],
   "source": [
    "#UCNets = pd.read_csv('data/a19i_all_COT_gpt4.csv')\n",
    "\n",
    "normalized_data_list = []\n",
    "error_lines = []\n",
    "\n",
    "for i, json_str in enumerate(UCNets['JSON']):\n",
    "    try:\n",
    "        parsed_obj = json.loads(json_str)\n",
    "        normalized_data_list.append(pd.json_normalize(parsed_obj))\n",
    "    except json.JSONDecodeError:\n",
    "        error_lines.append(i)\n",
    "        continue\n",
    "\n",
    "# Concatenate the normalized data into one DataFrame\n",
    "normalized_data = pd.concat(normalized_data_list, ignore_index=True)\n",
    "\n",
    "error_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbfe54e2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "UCNets = pd.concat([UCNets, normalized_data], axis=1)\n",
    "UCNets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83d9fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "UCNets.to_csv('data/a19i_all_COT_gpt4.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "“AI”",
   "language": "python",
   "name": "ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
