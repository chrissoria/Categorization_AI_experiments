{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78c77629",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.prompts.prompt import PromptTemplate #where we change the AI \"personality\"\n",
    "from dotenv import load_dotenv, find_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "129c22b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "API_KEY = os.environ.get(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a25a7471",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "#openai.api_key = os.getenv(\"api.txt\")\n",
    "COMPLETIONS_MODEL = \"text-davinci-002\"\n",
    "BETTER_COMPLETIONS_MODEL = \"text-davinci-003\" #for my purposes, this is better\n",
    "LONG_MODEL = \"gpt-3.5-turbo-16k\"\n",
    "REGULAR_MODEL = \"gpt-3.5-turbo\"\n",
    "GPT_4 = \"gpt-4\"\n",
    "\n",
    "chat = ChatOpenAI(temperature=0.7,\n",
    "                  openai_api_key = API_KEY,\n",
    "                  verbose=True,\n",
    "                  model_name=REGULAR_MODEL) #depending on how big of a task\n",
    "\n",
    "#below, we give the AI a \"personality\"\n",
    "template = \"\"\"The following is a conversation between a human data scientist and an AI who specializes in data categorization. The AI is direct and provides concise responses. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
    "\n",
    "Current conversation:\n",
    "{history}\n",
    "Data Scientist: {input}\n",
    "AI:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3954b9e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatOpenAI(cache=None, verbose=True, callbacks=None, callback_manager=None, tags=None, metadata=None, client=<class 'openai.api_resources.chat_completion.ChatCompletion'>, model_name='gpt-3.5-turbo', temperature=0.7, model_kwargs={}, openai_api_key='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', openai_api_base='', openai_organization='', openai_proxy='', request_timeout=None, max_retries=6, streaming=False, n=1, max_tokens=None, tiktoken_model_name=None)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b96d96b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/chrissoria/Documents/Research/Categorization_AI_experiments\n"
     ]
    }
   ],
   "source": [
    "os.chdir('/Users/chrissoria/Documents/Research/Categorization_AI_experiments')\n",
    "current_directory = os.getcwd()\n",
    "print(current_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5a7b7a15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a19i</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>relocated back to east coast - closer to my sons</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>move in together with my partner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>out of living with my friends, and into living...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>to take a new job in new york city (both becau...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wanted to live in my own place outside my pare...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                a19i\n",
       "0   relocated back to east coast - closer to my sons\n",
       "1                   move in together with my partner\n",
       "2  out of living with my friends, and into living...\n",
       "3  to take a new job in new york city (both becau...\n",
       "4  wanted to live in my own place outside my pare..."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "survey_participant_input = \"a19i\" #enter column name here\n",
    "\n",
    "UCNets = pd.read_excel(\"/Users/chrissoria/Documents/Research/UCNets_Classification/data/Raw_Cond_for_Coding_all_waves.xlsx\", engine='openpyxl',sheet_name=\"JOINT_DATA\",usecols=[survey_participant_input])\n",
    "UCNets = UCNets[survey_participant_input].dropna().unique()  # Drop NaN values and get unique elements\n",
    "\n",
    "survey_participant_responses = '; '.join(str(item) for item in UCNets) #what we will feed to the model\n",
    "\n",
    "UCNets = pd.DataFrame(UCNets, columns=[survey_participant_input])\n",
    "UCNets[survey_participant_input] = UCNets[survey_participant_input].astype(str).str.lower()\n",
    "UCNets[survey_participant_input] = UCNets[survey_participant_input].str.strip()\n",
    "UCNets = UCNets[UCNets[survey_participant_input] != ''].reset_index(drop=True) #trimming all empty rows\n",
    "\n",
    "UCNets = UCNets.iloc[:200]\n",
    "\n",
    "UCNets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b77e00c",
   "metadata": {},
   "source": [
    "Here, I'm trying to \"force\" the model to \"think\" in steps by first A. trying to process the response into its own words and B. having it interact with that object. That is, instead of all steps being given at once, I'm having it think in steps. \n",
    "\n",
    "This time, I will have it think in a \"chain,\" where I will have it output a response and then feed that response back to it in a seperate prompt. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6e5fb713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This respondent moved because they wanted to be closer to their job and switched jobs as well.\n"
     ]
    }
   ],
   "source": [
    "survey_input = UCNets['a19i'][72]  # Replace this with the actual survey input for each iteration if needed\n",
    "\n",
    "category = \"\"\"1. to start living with or to stay with partner/spouse. \\\n",
    "2. relationship change (divorce, breakup, etc). \\\n",
    "3. the respondent had a job/school/career change, including transferred. \\\n",
    "4. their partner had a job/school/career change, including transferred. \\\n",
    "5. financial reasons (rent is too expensive, pay raise, etc).\n",
    "6. Reasons related to specific housing features and preferences, different housing conditions\"\"\"\n",
    "\n",
    "example_JSON = \"\"\"{ \\\n",
    "\"1\": \"0\", \\\n",
    "\"2\": \"1\", \\\n",
    "\"3\": \"0\", \\\n",
    "\"4\": 1, \\\n",
    "\"5\": \"0\", \\\n",
    "\"6\": \"0\"\n",
    "}\"\"\"\n",
    "\n",
    "template_string1 = \"\"\"A survey respondent was asked, \"Why did you move?\" \\\n",
    "They responded with: \"{OBJECT}\" \\\n",
    "First, filter out anything in this response that doesn't answer the question, \"Why did you move?\" \\\n",
    "Second, pull out all the major reasons why they moved. \\\n",
    "Phrase your response succinctly starting with the words, 'This respondent moved because...'\"\"\"\n",
    "\n",
    "prompt_template1 = ChatPromptTemplate.from_template(template_string1)\n",
    "GPT_Responses1 = prompt_template1.format_messages(OBJECT=survey_input)\n",
    "\n",
    "TEST1 = chat(GPT_Responses1)\n",
    "TEST1_content = TEST1.content  \n",
    "\n",
    "print(TEST1_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fa226dc5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised APIError: Internal server error {\n",
      "    \"error\": {\n",
      "        \"message\": \"Internal server error\",\n",
      "        \"type\": \"auth_subrequest_error\",\n",
      "        \"param\": null,\n",
      "        \"code\": \"internal_error\"\n",
      "    }\n",
      "}\n",
      " 500 {'error': {'message': 'Internal server error', 'type': 'auth_subrequest_error', 'param': None, 'code': 'internal_error'}} {'Date': 'Fri, 20 Oct 2023 03:50:17 GMT', 'Content-Type': 'application/json; charset=utf-8', 'Content-Length': '166', 'Connection': 'keep-alive', 'vary': 'Origin', 'x-request-id': '978b812953a1a8d0530a55d0f1c60199', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '818e4b99de5617d2-SJC', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised APIError: Internal server error {\n",
      "    \"error\": {\n",
      "        \"message\": \"Internal server error\",\n",
      "        \"type\": \"auth_subrequest_error\",\n",
      "        \"param\": null,\n",
      "        \"code\": \"internal_error\"\n",
      "    }\n",
      "}\n",
      " 500 {'error': {'message': 'Internal server error', 'type': 'auth_subrequest_error', 'param': None, 'code': 'internal_error'}} {'Date': 'Fri, 20 Oct 2023 03:50:28 GMT', 'Content-Type': 'application/json; charset=utf-8', 'Content-Length': '166', 'Connection': 'keep-alive', 'vary': 'Origin', 'x-request-id': 'a1a4c6531ce2addcbe41766fd064f6a8', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '818e4bda4b5017d2-SJC', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised APIError: Internal server error {\n",
      "    \"error\": {\n",
      "        \"message\": \"Internal server error\",\n",
      "        \"type\": \"auth_subrequest_error\",\n",
      "        \"param\": null,\n",
      "        \"code\": \"internal_error\"\n",
      "    }\n",
      "}\n",
      " 500 {'error': {'message': 'Internal server error', 'type': 'auth_subrequest_error', 'param': None, 'code': 'internal_error'}} {'Date': 'Fri, 20 Oct 2023 03:50:42 GMT', 'Content-Type': 'application/json; charset=utf-8', 'Content-Length': '166', 'Connection': 'keep-alive', 'vary': 'Origin', 'x-request-id': '8f698841fd430fc2721676f633e8642e', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '818e4c353e0917d2-SJC', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised Timeout: Request timed out: HTTPSConnectionPool(host='api.openai.com', port=443): Read timed out. (read timeout=600).\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised APIError: Internal server error {\n",
      "    \"error\": {\n",
      "        \"message\": \"Internal server error\",\n",
      "        \"type\": \"auth_subrequest_error\",\n",
      "        \"param\": null,\n",
      "        \"code\": \"internal_error\"\n",
      "    }\n",
      "}\n",
      " 500 {'error': {'message': 'Internal server error', 'type': 'auth_subrequest_error', 'param': None, 'code': 'internal_error'}} {'Date': 'Fri, 20 Oct 2023 04:01:35 GMT', 'Content-Type': 'application/json; charset=utf-8', 'Content-Length': '166', 'Connection': 'keep-alive', 'vary': 'Origin', 'x-request-id': '021def2bd42d4f518b44c873d1021a97', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '818e5c25f9c9ce50-SJC', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised APIError: Internal server error {\n",
      "    \"error\": {\n",
      "        \"message\": \"Internal server error\",\n",
      "        \"type\": \"auth_subrequest_error\",\n",
      "        \"param\": null,\n",
      "        \"code\": \"internal_error\"\n",
      "    }\n",
      "}\n",
      " 500 {'error': {'message': 'Internal server error', 'type': 'auth_subrequest_error', 'param': None, 'code': 'internal_error'}} {'Date': 'Fri, 20 Oct 2023 04:01:44 GMT', 'Content-Type': 'application/json; charset=utf-8', 'Content-Length': '166', 'Connection': 'keep-alive', 'vary': 'Origin', 'x-request-id': '3ddfc0391eea1795b192c4555f1c39b3', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '818e5c5f2bbfce50-SJC', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised APIError: Internal server error {\n",
      "    \"error\": {\n",
      "        \"message\": \"Internal server error\",\n",
      "        \"type\": \"auth_subrequest_error\",\n",
      "        \"param\": null,\n",
      "        \"code\": \"internal_error\"\n",
      "    }\n",
      "}\n",
      " 500 {'error': {'message': 'Internal server error', 'type': 'auth_subrequest_error', 'param': None, 'code': 'internal_error'}} {'Date': 'Fri, 20 Oct 2023 04:01:56 GMT', 'Content-Type': 'application/json; charset=utf-8', 'Content-Length': '166', 'Connection': 'keep-alive', 'vary': 'Origin', 'x-request-id': '8d8165eae04473bce00d23b74e4456ef', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '818e5ca77868ce50-SJC', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised APIError: Internal server error {\n",
      "    \"error\": {\n",
      "        \"message\": \"Internal server error\",\n",
      "        \"type\": \"auth_subrequest_error\",\n",
      "        \"param\": null,\n",
      "        \"code\": \"internal_error\"\n",
      "    }\n",
      "}\n",
      " 500 {'error': {'message': 'Internal server error', 'type': 'auth_subrequest_error', 'param': None, 'code': 'internal_error'}} {'Date': 'Fri, 20 Oct 2023 04:02:10 GMT', 'Content-Type': 'application/json; charset=utf-8', 'Content-Length': '166', 'Connection': 'keep-alive', 'vary': 'Origin', 'x-request-id': 'f3b2aa5dc2b62c879d05ef60a7070ba7', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '818e5cfd8e15ce50-SJC', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised APIError: Internal server error {\n",
      "    \"error\": {\n",
      "        \"message\": \"Internal server error\",\n",
      "        \"type\": \"auth_subrequest_error\",\n",
      "        \"param\": null,\n",
      "        \"code\": \"internal_error\"\n",
      "    }\n",
      "}\n",
      " 500 {'error': {'message': 'Internal server error', 'type': 'auth_subrequest_error', 'param': None, 'code': 'internal_error'}} {'Date': 'Fri, 20 Oct 2023 04:02:30 GMT', 'Content-Type': 'application/json; charset=utf-8', 'Content-Length': '166', 'Connection': 'keep-alive', 'vary': 'Origin', 'x-request-id': '1bb89e3256ab46e65c4464acf908351e', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '818e5d7bc861ce50-SJC', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised APIError: Internal server error {\n",
      "    \"error\": {\n",
      "        \"message\": \"Internal server error\",\n",
      "        \"type\": \"auth_subrequest_error\",\n",
      "        \"param\": null,\n",
      "        \"code\": \"internal_error\"\n",
      "    }\n",
      "}\n",
      " 500 {'error': {'message': 'Internal server error', 'type': 'auth_subrequest_error', 'param': None, 'code': 'internal_error'}} {'Date': 'Fri, 20 Oct 2023 04:02:40 GMT', 'Content-Type': 'application/json; charset=utf-8', 'Content-Length': '166', 'Connection': 'keep-alive', 'vary': 'Origin', 'x-request-id': '703209c8cfba977823e306560138ceb7', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '818e5dba5b24ce50-SJC', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised APIError: Internal server error {\n",
      "    \"error\": {\n",
      "        \"message\": \"Internal server error\",\n",
      "        \"type\": \"auth_subrequest_error\",\n",
      "        \"param\": null,\n",
      "        \"code\": \"internal_error\"\n",
      "    }\n",
      "}\n",
      " 500 {'error': {'message': 'Internal server error', 'type': 'auth_subrequest_error', 'param': None, 'code': 'internal_error'}} {'Date': 'Fri, 20 Oct 2023 04:02:53 GMT', 'Content-Type': 'application/json; charset=utf-8', 'Content-Length': '166', 'Connection': 'keep-alive', 'vary': 'Origin', 'x-request-id': '2a1eb90110602db212813643eaf3dfc0', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '818e5e0abeffce50-SJC', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised APIError: Internal server error {\n",
      "    \"error\": {\n",
      "        \"message\": \"Internal server error\",\n",
      "        \"type\": \"auth_subrequest_error\",\n",
      "        \"param\": null,\n",
      "        \"code\": \"internal_error\"\n",
      "    }\n",
      "}\n",
      " 500 {'error': {'message': 'Internal server error', 'type': 'auth_subrequest_error', 'param': None, 'code': 'internal_error'}} {'Date': 'Fri, 20 Oct 2023 04:03:08 GMT', 'Content-Type': 'application/json; charset=utf-8', 'Content-Length': '166', 'Connection': 'keep-alive', 'vary': 'Origin', 'x-request-id': 'b9c5b2549951d2a5b40e88e79502d85c', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '818e5e6b6e2fce50-SJC', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised APIError: Internal server error {\n",
      "    \"error\": {\n",
      "        \"message\": \"Internal server error\",\n",
      "        \"type\": \"auth_subrequest_error\",\n",
      "        \"param\": null,\n",
      "        \"code\": \"internal_error\"\n",
      "    }\n",
      "}\n",
      " 500 {'error': {'message': 'Internal server error', 'type': 'auth_subrequest_error', 'param': None, 'code': 'internal_error'}} {'Date': 'Fri, 20 Oct 2023 04:03:17 GMT', 'Content-Type': 'application/json; charset=utf-8', 'Content-Length': '166', 'Connection': 'keep-alive', 'vary': 'Origin', 'x-request-id': '46e15c9d5bf5af912cf1655786ddfe60', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '818e5ea44937ce50-SJC', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised APIError: Internal server error {\n",
      "    \"error\": {\n",
      "        \"message\": \"Internal server error\",\n",
      "        \"type\": \"auth_subrequest_error\",\n",
      "        \"param\": null,\n",
      "        \"code\": \"internal_error\"\n",
      "    }\n",
      "}\n",
      " 500 {'error': {'message': 'Internal server error', 'type': 'auth_subrequest_error', 'param': None, 'code': 'internal_error'}} {'Date': 'Fri, 20 Oct 2023 04:03:27 GMT', 'Content-Type': 'application/json; charset=utf-8', 'Content-Length': '166', 'Connection': 'keep-alive', 'vary': 'Origin', 'x-request-id': '9b633562814d6394e0f994d2a52f5a4d', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '818e5ee19a04ce50-SJC', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised APIError: Internal server error {\n",
      "    \"error\": {\n",
      "        \"message\": \"Internal server error\",\n",
      "        \"type\": \"auth_subrequest_error\",\n",
      "        \"param\": null,\n",
      "        \"code\": \"internal_error\"\n",
      "    }\n",
      "}\n",
      " 500 {'error': {'message': 'Internal server error', 'type': 'auth_subrequest_error', 'param': None, 'code': 'internal_error'}} {'Date': 'Fri, 20 Oct 2023 04:03:37 GMT', 'Content-Type': 'application/json; charset=utf-8', 'Content-Length': '166', 'Connection': 'keep-alive', 'vary': 'Origin', 'x-request-id': '40c043a1194491fbc6b7aa46f292b56f', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '818e5f20288ace50-SJC', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised APIError: Internal server error {\n",
      "    \"error\": {\n",
      "        \"message\": \"Internal server error\",\n",
      "        \"type\": \"auth_subrequest_error\",\n",
      "        \"param\": null,\n",
      "        \"code\": \"internal_error\"\n",
      "    }\n",
      "}\n",
      " 500 {'error': {'message': 'Internal server error', 'type': 'auth_subrequest_error', 'param': None, 'code': 'internal_error'}} {'Date': 'Fri, 20 Oct 2023 04:03:49 GMT', 'Content-Type': 'application/json; charset=utf-8', 'Content-Length': '166', 'Connection': 'keep-alive', 'vary': 'Origin', 'x-request-id': 'f7756455b98d4fa9781a2f830fdd807d', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '818e5f6c6a40ce50-SJC', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised APIError: Internal server error {\n",
      "    \"error\": {\n",
      "        \"message\": \"Internal server error\",\n",
      "        \"type\": \"auth_subrequest_error\",\n",
      "        \"param\": null,\n",
      "        \"code\": \"internal_error\"\n",
      "    }\n",
      "}\n",
      " 500 {'error': {'message': 'Internal server error', 'type': 'auth_subrequest_error', 'param': None, 'code': 'internal_error'}} {'Date': 'Fri, 20 Oct 2023 04:03:58 GMT', 'Content-Type': 'application/json; charset=utf-8', 'Content-Length': '166', 'Connection': 'keep-alive', 'vary': 'Origin', 'x-request-id': '690347492eabde39c9347fb8d55710ec', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '818e5fa57b1fce50-SJC', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised APIError: Internal server error {\n",
      "    \"error\": {\n",
      "        \"message\": \"Internal server error\",\n",
      "        \"type\": \"auth_subrequest_error\",\n",
      "        \"param\": null,\n",
      "        \"code\": \"internal_error\"\n",
      "    }\n",
      "}\n",
      " 500 {'error': {'message': 'Internal server error', 'type': 'auth_subrequest_error', 'param': None, 'code': 'internal_error'}} {'Date': 'Fri, 20 Oct 2023 04:04:18 GMT', 'Content-Type': 'application/json; charset=utf-8', 'Content-Length': '166', 'Connection': 'keep-alive', 'vary': 'Origin', 'x-request-id': '1da5390ffc411f3a3e174cb5e13a5287', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '818e601e2b54ce50-SJC', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised APIError: Internal server error {\n",
      "    \"error\": {\n",
      "        \"message\": \"Internal server error\",\n",
      "        \"type\": \"auth_subrequest_error\",\n",
      "        \"param\": null,\n",
      "        \"code\": \"internal_error\"\n",
      "    }\n",
      "}\n",
      " 500 {'error': {'message': 'Internal server error', 'type': 'auth_subrequest_error', 'param': None, 'code': 'internal_error'}} {'Date': 'Fri, 20 Oct 2023 04:04:52 GMT', 'Content-Type': 'application/json; charset=utf-8', 'Content-Length': '166', 'Connection': 'keep-alive', 'vary': 'Origin', 'x-request-id': 'bbb0d6a9af94ff3f66ff9e5432cb075c', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '818e60f6dd8b1573-SJC', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised APIError: Internal server error {\n",
      "    \"error\": {\n",
      "        \"message\": \"Internal server error\",\n",
      "        \"type\": \"auth_subrequest_error\",\n",
      "        \"param\": null,\n",
      "        \"code\": \"internal_error\"\n",
      "    }\n",
      "}\n",
      " 500 {'error': {'message': 'Internal server error', 'type': 'auth_subrequest_error', 'param': None, 'code': 'internal_error'}} {'Date': 'Fri, 20 Oct 2023 04:05:05 GMT', 'Content-Type': 'application/json; charset=utf-8', 'Content-Length': '166', 'Connection': 'keep-alive', 'vary': 'Origin', 'x-request-id': 'd0cbe2f1017e2127e65ac4ac88ae5550', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '818e6146a9731573-SJC', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised APIError: Internal server error {\n",
      "    \"error\": {\n",
      "        \"message\": \"Internal server error\",\n",
      "        \"type\": \"auth_subrequest_error\",\n",
      "        \"param\": null,\n",
      "        \"code\": \"internal_error\"\n",
      "    }\n",
      "}\n",
      " 500 {'error': {'message': 'Internal server error', 'type': 'auth_subrequest_error', 'param': None, 'code': 'internal_error'}} {'Date': 'Fri, 20 Oct 2023 04:05:17 GMT', 'Content-Type': 'application/json; charset=utf-8', 'Content-Length': '166', 'Connection': 'keep-alive', 'vary': 'Origin', 'x-request-id': 'd11ca8e28802f39aaf821fc23871a1c7', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '818e618f9f5d1573-SJC', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised APIError: Internal server error {\n",
      "    \"error\": {\n",
      "        \"message\": \"Internal server error\",\n",
      "        \"type\": \"auth_subrequest_error\",\n",
      "        \"param\": null,\n",
      "        \"code\": \"internal_error\"\n",
      "    }\n",
      "}\n",
      " 500 {'error': {'message': 'Internal server error', 'type': 'auth_subrequest_error', 'param': None, 'code': 'internal_error'}} {'Date': 'Fri, 20 Oct 2023 04:05:37 GMT', 'Content-Type': 'application/json; charset=utf-8', 'Content-Length': '166', 'Connection': 'keep-alive', 'vary': 'Origin', 'x-request-id': '32d8d3d43cde230acf59094d3f81da00', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '818e620b5fc71573-SJC', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised APIError: Internal server error {\n",
      "    \"error\": {\n",
      "        \"message\": \"Internal server error\",\n",
      "        \"type\": \"auth_subrequest_error\",\n",
      "        \"param\": null,\n",
      "        \"code\": \"internal_error\"\n",
      "    }\n",
      "}\n",
      " 500 {'error': {'message': 'Internal server error', 'type': 'auth_subrequest_error', 'param': None, 'code': 'internal_error'}} {'Date': 'Fri, 20 Oct 2023 04:05:47 GMT', 'Content-Type': 'application/json; charset=utf-8', 'Content-Length': '166', 'Connection': 'keep-alive', 'vary': 'Origin', 'x-request-id': '56c86772dc8124b1e79c0ab028dcc088', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '818e62494bef1573-SJC', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised APIError: Internal server error {\n",
      "    \"error\": {\n",
      "        \"message\": \"Internal server error\",\n",
      "        \"type\": \"auth_subrequest_error\",\n",
      "        \"param\": null,\n",
      "        \"code\": \"internal_error\"\n",
      "    }\n",
      "}\n",
      " 500 {'error': {'message': 'Internal server error', 'type': 'auth_subrequest_error', 'param': None, 'code': 'internal_error'}} {'Date': 'Fri, 20 Oct 2023 04:06:00 GMT', 'Content-Type': 'application/json; charset=utf-8', 'Content-Length': '166', 'Connection': 'keep-alive', 'vary': 'Origin', 'x-request-id': '902c34dd828e27795a8a46be1e72381b', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '818e629fba9d1573-SJC', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised APIError: Internal server error {\n",
      "    \"error\": {\n",
      "        \"message\": \"Internal server error\",\n",
      "        \"type\": \"auth_subrequest_error\",\n",
      "        \"param\": null,\n",
      "        \"code\": \"internal_error\"\n",
      "    }\n",
      "}\n",
      " 500 {'error': {'message': 'Internal server error', 'type': 'auth_subrequest_error', 'param': None, 'code': 'internal_error'}} {'Date': 'Fri, 20 Oct 2023 04:06:26 GMT', 'Content-Type': 'application/json; charset=utf-8', 'Content-Length': '166', 'Connection': 'keep-alive', 'vary': 'Origin', 'x-request-id': '6eac221e434cf97ca51168f8857fefb1', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '818e634078411573-SJC', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised APIError: Internal server error {\n",
      "    \"error\": {\n",
      "        \"message\": \"Internal server error\",\n",
      "        \"type\": \"auth_subrequest_error\",\n",
      "        \"param\": null,\n",
      "        \"code\": \"internal_error\"\n",
      "    }\n",
      "}\n",
      " 500 {'error': {'message': 'Internal server error', 'type': 'auth_subrequest_error', 'param': None, 'code': 'internal_error'}} {'Date': 'Fri, 20 Oct 2023 04:06:55 GMT', 'Content-Type': 'application/json; charset=utf-8', 'Content-Length': '166', 'Connection': 'keep-alive', 'vary': 'Origin', 'x-request-id': 'e0e2106b653aa013bff70d0191360351', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '818e63f5ca2f1573-SJC', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised APIError: Internal server error {\n",
      "    \"error\": {\n",
      "        \"message\": \"Internal server error\",\n",
      "        \"type\": \"auth_subrequest_error\",\n",
      "        \"param\": null,\n",
      "        \"code\": \"internal_error\"\n",
      "    }\n",
      "}\n",
      " 500 {'error': {'message': 'Internal server error', 'type': 'auth_subrequest_error', 'param': None, 'code': 'internal_error'}} {'Date': 'Fri, 20 Oct 2023 04:07:10 GMT', 'Content-Type': 'application/json; charset=utf-8', 'Content-Length': '166', 'Connection': 'keep-alive', 'vary': 'Origin', 'x-request-id': '5d6bf2c41691e471574e10a63fec647e', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '818e64518a231573-SJC', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised APIError: Internal server error {\n",
      "    \"error\": {\n",
      "        \"message\": \"Internal server error\",\n",
      "        \"type\": \"auth_subrequest_error\",\n",
      "        \"param\": null,\n",
      "        \"code\": \"internal_error\"\n",
      "    }\n",
      "}\n",
      " 500 {'error': {'message': 'Internal server error', 'type': 'auth_subrequest_error', 'param': None, 'code': 'internal_error'}} {'Date': 'Fri, 20 Oct 2023 04:08:27 GMT', 'Content-Type': 'application/json; charset=utf-8', 'Content-Length': '166', 'Connection': 'keep-alive', 'vary': 'Origin', 'x-request-id': '6fe6c6b5d5fe768e03b05c7ee6b6d0e9', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '818e6636bd90ce54-SJC', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised APIError: Internal server error {\n",
      "    \"error\": {\n",
      "        \"message\": \"Internal server error\",\n",
      "        \"type\": \"auth_subrequest_error\",\n",
      "        \"param\": null,\n",
      "        \"code\": \"internal_error\"\n",
      "    }\n",
      "}\n",
      " 500 {'error': {'message': 'Internal server error', 'type': 'auth_subrequest_error', 'param': None, 'code': 'internal_error'}} {'Date': 'Fri, 20 Oct 2023 04:08:48 GMT', 'Content-Type': 'application/json; charset=utf-8', 'Content-Length': '166', 'Connection': 'keep-alive', 'vary': 'Origin', 'x-request-id': '5451845efdd15b9984181081d8b507ab', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '818e66b4ece3ce54-SJC', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n"
     ]
    }
   ],
   "source": [
    "# Initialize an empty list to store the results\n",
    "results_list = []\n",
    "\n",
    "# Loop through the entire 'a19i' column\n",
    "for survey_input in UCNets['a19i']:\n",
    "    \n",
    "    template_string1 = \"\"\"A survey respondent was asked, \"Why did you move?\" \\\n",
    "    They responded with: \"{OBJECT}\" \\\n",
    "    First, filter out anything in this response that doesn't answer the question, \"Why did you move?\" \\\n",
    "    Second, pull out all the major reasons why they moved without being too specific. \\\n",
    "    Phrase your response as succinctly starting with the words, 'This respondent moved because...'\"\"\"\n",
    "\n",
    "    prompt_template1 = ChatPromptTemplate.from_template(template_string1)\n",
    "    GPT_Responses1 = prompt_template1.format_messages(OBJECT=survey_input)\n",
    "\n",
    "    TEST1 = chat(GPT_Responses1)\n",
    "    TEST1_content = TEST1.content  # Assuming TEST1.content gives the actual content\n",
    "\n",
    "    # Append the result to the list\n",
    "    results_list.append(TEST1_content)\n",
    "\n",
    "# Convert the results list to a new column in the DataFrame\n",
    "UCNets['reasons'] = pd.Series(results_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "819543a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "UCNets.to_csv('data/a19i_reasons.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "68000b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = ChatOpenAI(temperature=0.7,\n",
    "                  openai_api_key = API_KEY,\n",
    "                  verbose=True,\n",
    "                  model_name=REGULAR_MODEL) #depending on how big of a task\n",
    "\n",
    "for i in range(1, 4):  # Loop 3 times, i will be 1, 2, 3\n",
    "    results_list2 = []\n",
    "    \n",
    "    for survey_input in UCNets['reasons']:\n",
    "        template_string2 = \"\"\"A survey respondent was asked, \"Why did you move?\" \\\n",
    "        {OBJECT} \\\n",
    "        Please determine whether their reasons for moving fall in this list of categories: \\\n",
    "        {CATEGORY} \\\n",
    "        Provide your answer as a 1 if yes and a 0 if no in JSON format \\\n",
    "        Here's an example of how you should format your response: \\\n",
    "        {EXAMPLE}\"\"\"\n",
    "\n",
    "        prompt_template2 = ChatPromptTemplate.from_template(template_string2)\n",
    "        # prompt_template2.messages[0].prompt  # Uncomment this if you want to see the prompt template\n",
    "\n",
    "        GPT_Responses2 = prompt_template2.format_messages(\n",
    "                        OBJECT=survey_input,\n",
    "                        CATEGORY=category,\n",
    "                        EXAMPLE=example_JSON)\n",
    "\n",
    "        TEST2 = chat(GPT_Responses2)\n",
    "        TEST2_content = TEST2.content\n",
    "        \n",
    "        # Append the result to the list\n",
    "        results_list2.append(TEST2_content)\n",
    "\n",
    "    # Create a new column in the DataFrame\n",
    "    column_name = f'categorization{i}'  # Will be 'categorization1', 'categorization2', 'categorization3'\n",
    "    UCNets[column_name] = pd.Series(results_list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7b299367",
   "metadata": {},
   "outputs": [],
   "source": [
    "UCNets.to_csv('data/a19i_reasons.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "50b22708",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Initialize an empty list to store the results\n",
    "results_list3 = []\n",
    "\n",
    "# Loop through the entire 'a19i' column with index\n",
    "for i, survey_input in enumerate(UCNets['a19i']):\n",
    "    \n",
    "    # Get the categorization values for the current row\n",
    "    categorization1 = UCNets['categorization1'].iloc[i]\n",
    "    categorization2 = UCNets['categorization2'].iloc[i]\n",
    "    categorization3 = UCNets['categorization3'].iloc[i]\n",
    "    \n",
    "    template_string1 = \"\"\"A survey respondent was asked, \"Why did you move?\" \\\n",
    "        {OBJECT} \\\n",
    "        I asked you three times whether their reasons for moving fall in this list of categories: \\\n",
    "        {CATEGORY} \\\n",
    "        You replied with A. {JSON1}, /\n",
    "        B. {JSON2}, /\n",
    "        C. {JSON3}. /\n",
    "        Make your response be ONLY me the letter that corresponds to the best categorization with no other text.\"\"\"\n",
    "\n",
    "    prompt_template1 = ChatPromptTemplate.from_template(template_string1)\n",
    "    GPT_Responses1 = prompt_template1.format_messages(OBJECT=survey_input,\n",
    "                                                      CATEGORY=category,\n",
    "                                                     JSON1=categorization1,\n",
    "                                                     JSON2=categorization2,\n",
    "                                                     JSON3=categorization3)\n",
    "\n",
    "    TEST3 = chat(GPT_Responses1)\n",
    "    TEST3_content = TEST3.content  # Assuming TEST1.content gives the actual content\n",
    "\n",
    "    # Append the result to the list\n",
    "    results_list3.append(TEST3_content)\n",
    "\n",
    "# Convert the results list to a new column in the DataFrame\n",
    "UCNets['TOT'] = pd.Series(results_list3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "28f18c86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B\n"
     ]
    }
   ],
   "source": [
    "print(UCNets['TOT'][13])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f97f9515",
   "metadata": {},
   "outputs": [],
   "source": [
    "UCNets.to_csv('data/a19i_reasons.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "125ce690",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_data_list = []\n",
    "error_lines = []\n",
    "\n",
    "for i, json_str in enumerate(UCNets['TOT']):\n",
    "    try:\n",
    "        parsed_obj = json.loads(json_str)\n",
    "        normalized_data_list.append(pd.json_normalize(parsed_obj))\n",
    "    except json.JSONDecodeError:\n",
    "        error_lines.append(i)\n",
    "        continue\n",
    "\n",
    "# Concatenate the normalized data into one DataFrame\n",
    "normalized_data = pd.concat(normalized_data_list, ignore_index=True)\n",
    "\n",
    "error_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "fbfe54e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a19i</th>\n",
       "      <th>reasons</th>\n",
       "      <th>categorization1</th>\n",
       "      <th>categorization2</th>\n",
       "      <th>categorization3</th>\n",
       "      <th>TOT</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>responses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>relocated back to east coast - closer to my sons</td>\n",
       "      <td>This respondent moved because they relocated b...</td>\n",
       "      <td>{\"1\": \"0\", \"2\": \"0\", \"3\": \"0\", \"4\": \"0\", \"5\": ...</td>\n",
       "      <td>{\\n    \"1\": \"0\",\\n    \"2\": \"0\",\\n    \"3\": \"0\",...</td>\n",
       "      <td>{\\n   \"1\": \"0\",\\n   \"2\": \"0\",\\n   \"3\": \"0\",\\n ...</td>\n",
       "      <td>{\\n   \"1\": \"0\",\\n   \"2\": \"0\",\\n   \"3\": \"1\",\\n ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>move in together with my partner</td>\n",
       "      <td>This respondent moved because they wanted to l...</td>\n",
       "      <td>{\\n\"1\": \"1\",\\n\"2\": \"0\",\\n\"3\": \"0\",\\n\"4\": \"0\",\\...</td>\n",
       "      <td>{\"1\": \"1\", \"2\": \"0\", \"3\": \"0\", \"4\": \"0\", \"5\": ...</td>\n",
       "      <td>{ \"1\": \"1\", \"2\": \"0\", \"3\": \"0\", \"4\": \"0\", \"5\":...</td>\n",
       "      <td>{\"1\": \"1\", \"2\": \"0\", \"3\": \"0\", \"4\": \"0\", \"5\": ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>out of living with my friends, and into living...</td>\n",
       "      <td>This respondent moved because they wanted to l...</td>\n",
       "      <td>{\\n    \"1\": \"1\",\\n    \"2\": \"0\",\\n    \"3\": \"0\",...</td>\n",
       "      <td>{\\n    \"1\": \"1\",\\n    \"2\": \"0\",\\n    \"3\": \"0\",...</td>\n",
       "      <td>{\\n    \"1\": \"1\",\\n    \"2\": \"0\",\\n    \"3\": \"0\",...</td>\n",
       "      <td>{\\n    \"1\": \"1\",\\n    \"2\": \"0\",\\n    \"3\": \"0\",...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>to take a new job in new york city (both becau...</td>\n",
       "      <td>This respondent moved because they wanted to c...</td>\n",
       "      <td>{\"1\": \"0\", \"2\": \"0\", \"3\": \"1\", \"4\": \"0\", \"5\": ...</td>\n",
       "      <td>{\\n    \"1\": \"0\",\\n    \"2\": \"0\",\\n    \"3\": \"1\",...</td>\n",
       "      <td>{\"1\": \"0\", \"2\": \"0\", \"3\": \"1\", \"4\": \"0\", \"5\": ...</td>\n",
       "      <td>{\\n    \"1\": \"0\",\\n    \"2\": \"0\",\\n    \"3\": \"1\",...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wanted to live in my own place outside my pare...</td>\n",
       "      <td>This respondent moved because they wanted to l...</td>\n",
       "      <td>{\\n    \"1\": \"0\",\\n    \"2\": \"0\",\\n    \"3\": \"0\",...</td>\n",
       "      <td>{\\n\"1\": \"0\",\\n\"2\": \"0\",\\n\"3\": \"0\",\\n\"4\": \"0\",\\...</td>\n",
       "      <td>{\\n   \"1\": \"0\",\\n   \"2\": \"0\",\\n   \"3\": \"0\",\\n ...</td>\n",
       "      <td>{\\n    \"1\": \"0\",\\n    \"2\": \"0\",\\n    \"3\": \"0\",...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>opportunity came up</td>\n",
       "      <td>This respondent moved because an opportunity c...</td>\n",
       "      <td>{\"1\": \"0\", \"2\": \"0\", \"3\": \"1\", \"4\": \"0\", \"5\": ...</td>\n",
       "      <td>{ \"1\": \"0\", \"2\": \"0\", \"3\": \"1\", \"4\": \"0\", \"5\":...</td>\n",
       "      <td>{\\n    \"1\": \"0\",\\n    \"2\": \"0\",\\n    \"3\": \"1\",...</td>\n",
       "      <td>{\\n    \"1\": \"0\",\\n    \"2\": \"0\",\\n    \"3\": \"1\",...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>we preferred the environment/climate in anothe...</td>\n",
       "      <td>This respondent moved because they preferred t...</td>\n",
       "      <td>{\\n    \"1\": \"0\",\\n    \"2\": \"0\",\\n    \"3\": \"0\",...</td>\n",
       "      <td>{\\n    \"1\": \"0\",\\n    \"2\": \"0\",\\n    \"3\": \"0\",...</td>\n",
       "      <td>{\\n    \"1\": \"0\",\\n    \"2\": \"0\",\\n    \"3\": \"0\",...</td>\n",
       "      <td>{\\n    \"1\": \"0\",\\n    \"2\": \"0\",\\n    \"3\": \"0\",...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>we wanted to live in a location we'd like more.</td>\n",
       "      <td>This respondent moved because they wanted to l...</td>\n",
       "      <td>{ \"1\": \"0\", \"2\": \"0\", \"3\": \"0\", \"4\": \"0\", \"5\":...</td>\n",
       "      <td>{\\n    \"1\": \"0\",\\n    \"2\": \"0\",\\n    \"3\": \"0\",...</td>\n",
       "      <td>{\"1\": \"0\", \"2\": \"0\", \"3\": \"0\", \"4\": \"0\", \"5\": ...</td>\n",
       "      <td>{\"1\": \"0\", \"2\": \"0\", \"3\": \"0\", \"4\": \"0\", \"5\": ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>downsizing/retiring</td>\n",
       "      <td>This respondent moved because they were downsi...</td>\n",
       "      <td>{\"1\": \"0\", \"2\": \"0\", \"3\": \"0\", \"4\": \"0\", \"5\": ...</td>\n",
       "      <td>{\"1\": \"0\", \"2\": \"0\", \"3\": \"0\", \"4\": \"0\", \"5\": ...</td>\n",
       "      <td>{\\n    \"1\": \"0\",\\n    \"2\": \"0\",\\n    \"3\": \"0\",...</td>\n",
       "      <td>{\\n    \"1\": \"0\",\\n    \"2\": \"0\",\\n    \"3\": \"0\",...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>we moved to washington state in 6/16 for one y...</td>\n",
       "      <td>This respondent moved because they wanted to t...</td>\n",
       "      <td>{ \"1\": \"0\", \"2\": \"0\", \"3\": \"0\", \"4\": \"0\", \"5\":...</td>\n",
       "      <td>{\\n    \"1\": \"0\",\\n    \"2\": \"0\",\\n    \"3\": \"0\",...</td>\n",
       "      <td>{\\n    \"1\": \"0\",\\n    \"2\": \"0\",\\n    \"3\": \"0\",...</td>\n",
       "      <td>{\\n    \"1\": \"0\",\\n    \"2\": \"0\",\\n    \"3\": \"0\",...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  a19i  \\\n",
       "0     relocated back to east coast - closer to my sons   \n",
       "1                     move in together with my partner   \n",
       "2    out of living with my friends, and into living...   \n",
       "3    to take a new job in new york city (both becau...   \n",
       "4    wanted to live in my own place outside my pare...   \n",
       "..                                                 ...   \n",
       "195                                opportunity came up   \n",
       "196  we preferred the environment/climate in anothe...   \n",
       "197    we wanted to live in a location we'd like more.   \n",
       "198                                downsizing/retiring   \n",
       "199  we moved to washington state in 6/16 for one y...   \n",
       "\n",
       "                                               reasons  \\\n",
       "0    This respondent moved because they relocated b...   \n",
       "1    This respondent moved because they wanted to l...   \n",
       "2    This respondent moved because they wanted to l...   \n",
       "3    This respondent moved because they wanted to c...   \n",
       "4    This respondent moved because they wanted to l...   \n",
       "..                                                 ...   \n",
       "195  This respondent moved because an opportunity c...   \n",
       "196  This respondent moved because they preferred t...   \n",
       "197  This respondent moved because they wanted to l...   \n",
       "198  This respondent moved because they were downsi...   \n",
       "199  This respondent moved because they wanted to t...   \n",
       "\n",
       "                                       categorization1  \\\n",
       "0    {\"1\": \"0\", \"2\": \"0\", \"3\": \"0\", \"4\": \"0\", \"5\": ...   \n",
       "1    {\\n\"1\": \"1\",\\n\"2\": \"0\",\\n\"3\": \"0\",\\n\"4\": \"0\",\\...   \n",
       "2    {\\n    \"1\": \"1\",\\n    \"2\": \"0\",\\n    \"3\": \"0\",...   \n",
       "3    {\"1\": \"0\", \"2\": \"0\", \"3\": \"1\", \"4\": \"0\", \"5\": ...   \n",
       "4    {\\n    \"1\": \"0\",\\n    \"2\": \"0\",\\n    \"3\": \"0\",...   \n",
       "..                                                 ...   \n",
       "195  {\"1\": \"0\", \"2\": \"0\", \"3\": \"1\", \"4\": \"0\", \"5\": ...   \n",
       "196  {\\n    \"1\": \"0\",\\n    \"2\": \"0\",\\n    \"3\": \"0\",...   \n",
       "197  { \"1\": \"0\", \"2\": \"0\", \"3\": \"0\", \"4\": \"0\", \"5\":...   \n",
       "198  {\"1\": \"0\", \"2\": \"0\", \"3\": \"0\", \"4\": \"0\", \"5\": ...   \n",
       "199  { \"1\": \"0\", \"2\": \"0\", \"3\": \"0\", \"4\": \"0\", \"5\":...   \n",
       "\n",
       "                                       categorization2  \\\n",
       "0    {\\n    \"1\": \"0\",\\n    \"2\": \"0\",\\n    \"3\": \"0\",...   \n",
       "1    {\"1\": \"1\", \"2\": \"0\", \"3\": \"0\", \"4\": \"0\", \"5\": ...   \n",
       "2    {\\n    \"1\": \"1\",\\n    \"2\": \"0\",\\n    \"3\": \"0\",...   \n",
       "3    {\\n    \"1\": \"0\",\\n    \"2\": \"0\",\\n    \"3\": \"1\",...   \n",
       "4    {\\n\"1\": \"0\",\\n\"2\": \"0\",\\n\"3\": \"0\",\\n\"4\": \"0\",\\...   \n",
       "..                                                 ...   \n",
       "195  { \"1\": \"0\", \"2\": \"0\", \"3\": \"1\", \"4\": \"0\", \"5\":...   \n",
       "196  {\\n    \"1\": \"0\",\\n    \"2\": \"0\",\\n    \"3\": \"0\",...   \n",
       "197  {\\n    \"1\": \"0\",\\n    \"2\": \"0\",\\n    \"3\": \"0\",...   \n",
       "198  {\"1\": \"0\", \"2\": \"0\", \"3\": \"0\", \"4\": \"0\", \"5\": ...   \n",
       "199  {\\n    \"1\": \"0\",\\n    \"2\": \"0\",\\n    \"3\": \"0\",...   \n",
       "\n",
       "                                       categorization3  \\\n",
       "0    {\\n   \"1\": \"0\",\\n   \"2\": \"0\",\\n   \"3\": \"0\",\\n ...   \n",
       "1    { \"1\": \"1\", \"2\": \"0\", \"3\": \"0\", \"4\": \"0\", \"5\":...   \n",
       "2    {\\n    \"1\": \"1\",\\n    \"2\": \"0\",\\n    \"3\": \"0\",...   \n",
       "3    {\"1\": \"0\", \"2\": \"0\", \"3\": \"1\", \"4\": \"0\", \"5\": ...   \n",
       "4    {\\n   \"1\": \"0\",\\n   \"2\": \"0\",\\n   \"3\": \"0\",\\n ...   \n",
       "..                                                 ...   \n",
       "195  {\\n    \"1\": \"0\",\\n    \"2\": \"0\",\\n    \"3\": \"1\",...   \n",
       "196  {\\n    \"1\": \"0\",\\n    \"2\": \"0\",\\n    \"3\": \"0\",...   \n",
       "197  {\"1\": \"0\", \"2\": \"0\", \"3\": \"0\", \"4\": \"0\", \"5\": ...   \n",
       "198  {\\n    \"1\": \"0\",\\n    \"2\": \"0\",\\n    \"3\": \"0\",...   \n",
       "199  {\\n    \"1\": \"0\",\\n    \"2\": \"0\",\\n    \"3\": \"0\",...   \n",
       "\n",
       "                                                   TOT  1  2  3  4  5  6  \\\n",
       "0    {\\n   \"1\": \"0\",\\n   \"2\": \"0\",\\n   \"3\": \"1\",\\n ...  0  0  1  0  0  0   \n",
       "1    {\"1\": \"1\", \"2\": \"0\", \"3\": \"0\", \"4\": \"0\", \"5\": ...  1  0  0  0  0  0   \n",
       "2    {\\n    \"1\": \"1\",\\n    \"2\": \"0\",\\n    \"3\": \"0\",...  1  0  0  0  0  0   \n",
       "3    {\\n    \"1\": \"0\",\\n    \"2\": \"0\",\\n    \"3\": \"1\",...  0  0  1  0  0  0   \n",
       "4    {\\n    \"1\": \"0\",\\n    \"2\": \"0\",\\n    \"3\": \"0\",...  0  0  0  0  0  1   \n",
       "..                                                 ... .. .. .. .. .. ..   \n",
       "195  {\\n    \"1\": \"0\",\\n    \"2\": \"0\",\\n    \"3\": \"1\",...  0  0  1  0  0  0   \n",
       "196  {\\n    \"1\": \"0\",\\n    \"2\": \"0\",\\n    \"3\": \"0\",...  0  0  0  0  0  1   \n",
       "197  {\"1\": \"0\", \"2\": \"0\", \"3\": \"0\", \"4\": \"0\", \"5\": ...  0  0  0  0  0  1   \n",
       "198  {\\n    \"1\": \"0\",\\n    \"2\": \"0\",\\n    \"3\": \"0\",...  0  0  0  0  0  1   \n",
       "199  {\\n    \"1\": \"0\",\\n    \"2\": \"0\",\\n    \"3\": \"0\",...  0  0  0  0  0  1   \n",
       "\n",
       "    responses  \n",
       "0         NaN  \n",
       "1         NaN  \n",
       "2         NaN  \n",
       "3         NaN  \n",
       "4         NaN  \n",
       "..        ...  \n",
       "195       NaN  \n",
       "196       NaN  \n",
       "197       NaN  \n",
       "198       NaN  \n",
       "199       NaN  \n",
       "\n",
       "[200 rows x 13 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "UCNets = pd.concat([UCNets, normalized_data], axis=1)\n",
    "UCNets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d83d9fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "UCNets.to_csv('data/a19i_all_TOT.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108f2da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_participant_input = \"a19i\" #enter column name here\n",
    "\n",
    "UCNets = pd.read_excel(\"/Users/chrissoria/Documents/Research/UCNets_Classification/data/Raw_Cond_for_Coding_all_waves.xlsx\", engine='openpyxl',sheet_name=\"JOINT_DATA\",usecols=[survey_participant_input])\n",
    "UCNets = UCNets[survey_participant_input].dropna().unique()  # Drop NaN values and get unique elements\n",
    "\n",
    "survey_participant_responses = '; '.join(str(item) for item in UCNets) #what we will feed to the model\n",
    "\n",
    "UCNets = pd.DataFrame(UCNets, columns=[survey_participant_input])\n",
    "UCNets[survey_participant_input] = UCNets[survey_participant_input].astype(str).str.lower()\n",
    "UCNets[survey_participant_input] = UCNets[survey_participant_input].str.strip()\n",
    "UCNets = UCNets[UCNets[survey_participant_input] != ''].reset_index(drop=True) #trimming all empty rows\n",
    "\n",
    "UCNets = UCNets.iloc[:200]\n",
    "\n",
    "UCNets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660bea9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_input = UCNets['a19i'][99] \n",
    "\n",
    "category = \"\"\"1. Associated with starting to live with or continuing to live with a partner or spouse \\\n",
    "for the sake of maintaining a relationship are encompassed in this category. \\\n",
    "It includes situations where individuals choose to move in with their partner or spouse or \\\n",
    "decide to continue cohabitation with them. \\\n",
    "2. Related to the end of a romantic relationship, including divorce, \\\n",
    "breakup, or other similar circumstances that result in the termination of the relationship. \\\n",
    "3. Associated with the person's job, school, or career. It covers situations such as job transfers, \\\n",
    "retirement, starting a new job, or wanting to be closer to the workplace for convenience or commuting purposes. \\\n",
    "4. Associated with the partner's job, school, or career. It covers situations such as partner job transfers, \\\n",
    "retirement, starting a new job, or wanting to be closer to the workplace for convenience or commuting purposes. \\\n",
    "5. Related to financial factors influencing housing decisions. It includes situations such as experiencing \\\n",
    "an increase in rent, being unable to afford the current housing expenses, finding a more affordable option, \\\n",
    "and receiving a pay raise that allows for a change in housing arrangements. \\\n",
    "6. Reasons related to specific housing features and preferences. It includes motivations such \\\n",
    "as the desire to purchase a house, downsizing to a smaller place, acquiring a larger residence, \\\n",
    "seeking a better-quality house, and the preference for having a yard.\"\"\"\n",
    "\n",
    "example_JSON = \"\"\"{ \\\n",
    "\"1\": \"0\", \\\n",
    "\"2\": \"1\", \\\n",
    "\"3\": \"0\", \\\n",
    "\"4\": 1, \\\n",
    "\"5\": \"0\", \\\n",
    "\"6\": \"0\"\n",
    "}\"\"\"\n",
    "\n",
    "template_string1 = \"\"\"A survey respondent was asked, \"Why did you move?\" \\\n",
    "They responded with: \"{OBJECT}\" \\\n",
    "First, filter out anything in this response that doesn't answer the question, \"Why did you move?\" \\\n",
    "Second, succinctly pull out all the major reasons why they moved. \\\n",
    "Format your response in a as few words as possible starting with the words, 'This respondent moved because...'\"\"\"\n",
    "\n",
    "prompt_template1 = ChatPromptTemplate.from_template(template_string1)\n",
    "prompt_template1.messages[0].prompt #this will show us our prompt template\n",
    "\n",
    "GPT_Responses1 = prompt_template1.format_messages(\n",
    "                    OBJECT=survey_input)\n",
    "\n",
    "TEST1 = chat(GPT_Responses1)\n",
    "TEST1 = TEST1.content\n",
    "\n",
    "template_string2 = \"\"\"A survey respondent was asked, \"Why did you move?\" \\\n",
    "\"{OBJECT}\" \\\n",
    "Please determine how many of the following reasons for moving they provide from this list: \\\n",
    "{CATEGORY} \\\n",
    "Next, provide your answer as a 1 if yes and a 0 if no in JSON format \\\n",
    "Here's an example of how you should format your response: \\\n",
    "{EXAMPLE}\"\"\"\n",
    "\n",
    "prompt_template2 = ChatPromptTemplate.from_template(template_string2)\n",
    "prompt_template2.messages[0].prompt #this will show us our prompt template\n",
    "\n",
    "GPT_Responses2 = prompt_template2.format_messages(\n",
    "                    OBJECT=TEST1,\n",
    "                    CATEGORY=category,\n",
    "                    EXAMPLE=example_JSON)\n",
    "\n",
    "TEST2 = chat(GPT_Responses2)\n",
    "TEST2 = TEST2.content\n",
    "print(TEST1)\n",
    "print(TEST2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a71c6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(UCNets)):\n",
    "    survey_input = UCNets['a19i'][i]\n",
    "    response = prompt_template1.format_messages(\n",
    "                    OBJECT=survey_input)\n",
    "\n",
    "    response = chat(response)\n",
    "    \n",
    "    # Assuming a successful attempt means a non-empty response\n",
    "    if response.content:\n",
    "        print(f\"Successful attempt for row number for chain 1: {i}\")\n",
    "    \n",
    "    UCNets.at[i, 'Key_Reasons'] = response.content\n",
    "    \n",
    "for i in range(len(UCNets)):\n",
    "    survey_input = UCNets['Key_Reasons'][i]\n",
    "    response = prompt_template2.format_messages(\n",
    "                    OBJECT=survey_input,\n",
    "                    CATEGORY=category,\n",
    "                    EXAMPLE=example_JSON)\n",
    "\n",
    "    response = chat(response)\n",
    "    \n",
    "    # Assuming a successful attempt means a non-empty response\n",
    "    if response.content:\n",
    "        print(f\"Successful attempt for row number for chain 2: {i}\")\n",
    "    \n",
    "    UCNets.at[i, 'JSON'] = response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08a1f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_data_list = []\n",
    "error_lines = []\n",
    "\n",
    "for i, json_str in enumerate(UCNets['JSON']):\n",
    "    try:\n",
    "        parsed_obj = json.loads(json_str)\n",
    "        normalized_data_list.append(pd.json_normalize(parsed_obj))\n",
    "    except json.JSONDecodeError:\n",
    "        error_lines.append(i)\n",
    "        continue\n",
    "\n",
    "# Concatenate the normalized data into one DataFrame\n",
    "normalized_data = pd.concat(normalized_data_list, ignore_index=True)\n",
    "\n",
    "error_lines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cab96f2",
   "metadata": {},
   "source": [
    "Later, I will write in a mechanism to deal with these errors. For now, I will fix it manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d831c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_df = UCNets.loc[error_lines].copy()\n",
    "error_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61d41b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "UCNets.to_csv('data/a19i_all_COT_descriptive.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ccf3b39",
   "metadata": {},
   "source": [
    "This is after I fixed up a line to make it JSON. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d512f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "UCNets = pd.read_csv('data/a19i_all_COT_descriptive.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62555bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_data_list = []\n",
    "error_lines = []\n",
    "\n",
    "for i, json_str in enumerate(UCNets['JSON']):\n",
    "    try:\n",
    "        parsed_obj = json.loads(json_str)\n",
    "        normalized_data_list.append(pd.json_normalize(parsed_obj))\n",
    "    except json.JSONDecodeError:\n",
    "        error_lines.append(i)\n",
    "        continue\n",
    "\n",
    "# Concatenate the normalized data into one DataFrame\n",
    "normalized_data = pd.concat(normalized_data_list, ignore_index=True)\n",
    "\n",
    "error_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffcec008",
   "metadata": {},
   "outputs": [],
   "source": [
    "UCNets = pd.concat([UCNets, normalized_data], axis=1)\n",
    "UCNets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a4185b",
   "metadata": {},
   "outputs": [],
   "source": [
    "UCNets.to_csv('data/a19i_all_COT_descriptive.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc72508",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
